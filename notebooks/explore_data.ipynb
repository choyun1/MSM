{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "|| MSM INITIALIZATION\n",
      "================================================================================\n",
      "Setting time zone...\n",
      "Setting paths...\n",
      "Importing sigtools...\n",
      "Setting up sounddevice...\n",
      "Importing level adjustments...\n",
      "Setting eligible BUG words...\n",
      "Preparing to create long-term spectrum matched noise...\n",
      "Set values for tone pattern synthesis...\n",
      "================================================================================\n",
      "Initialization complete!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"Times New Roman\"]\n",
    "})\n",
    "# import seaborn as sns\n",
    "# sns.set_theme(context=\"poster\", font_scale=1)\n",
    "\n",
    "sys.path.append(\"/home/acho/Sync/KiddLab/MSM/src\")\n",
    "from utils.stim_tools import *\n",
    "\n",
    "import pymc3 as pm\n",
    "import arviz as az\n",
    "import theano.tensor as tt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expt v1.1\n",
    "### 09/09/21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for comparing answers word-by-word\n",
    "def compare_answers(str1, str2):\n",
    "    return np.array([int(str1.split(\" \")[i] == str2.split(\" \")[i])\n",
    "                     for i in range(len(str1.split(\" \")))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_df = pd.read_csv(PROJ_DIR/\"assets\"/\"stimuli\"/\"stimulus_database.csv\")\n",
    "data_fnames = sorted(os.listdir(DATA_DIR))\n",
    "\n",
    "# Read in each file \n",
    "all_runs_df = pd.DataFrame()\n",
    "# for fname in data_fnames:\n",
    "# for fname in (data_fnames[:-3] + [data_fnames[-1]]):\n",
    "for fname in data_fnames[:-3]:\n",
    "# for fname in [data_fnames[-1]]:\n",
    "    curr_df = pd.read_csv(DATA_DIR/fname)\n",
    "    merge_df = pd.merge(curr_df, stim_df)\n",
    "    all_runs_df = pd.concat([all_runs_df, merge_df])\n",
    "all_runs_df = all_runs_df.reset_index(drop=True)\n",
    "\n",
    "# Remove practice blocks and convert the block_num data type to int\n",
    "all_runs_df = all_runs_df[(all_runs_df[\"block_num\"] != \"P1\") &\n",
    "                          (all_runs_df[\"block_num\"] != \"P2\") &\n",
    "                          (all_runs_df[\"block_num\"] != \"P3\")].reset_index(drop=True)\n",
    "all_runs_df.loc[:, \"block_num\"] = all_runs_df.loc[:, \"block_num\"].astype(int)\n",
    "\n",
    "# Modify the speech correct count to proportions\n",
    "speech_ID_rows = all_runs_df[(all_runs_df[\"task_type\"] == \"speech_ID\")].index\n",
    "all_runs_df.loc[speech_ID_rows, \"correct\"] /= 5\n",
    "\n",
    "# Get subject IDs and number of subjects\n",
    "subject_IDs = sorted(list(set(all_runs_df[\"subject_ID\"].values)))\n",
    "n_subjects = len(subject_IDs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percent correct plots\n",
    "* Can show individual plots easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process data\n",
    "only_target = all_runs_df[all_runs_df[\"is_target\"]]\n",
    "subject_avg = only_target.groupby([\"subject_ID\",\n",
    "                                   \"task_type\",\n",
    "                                   \"stim_type\",\n",
    "                                   \"amplitude\"])\n",
    "group_avg = only_target.groupby([\"task_type\",\n",
    "                                 \"stim_type\",\n",
    "                                 \"amplitude\"])\n",
    "subject_key_list = []\n",
    "subject_item_list = []\n",
    "for key, item in subject_avg:\n",
    "    subject_key_list.append(key)\n",
    "    subject_item_list.append(item[\"correct\"].values.mean())\n",
    "subject_key_list = [(row[0], row[1] + \"-\" + row[2]) for row in subject_key_list]\n",
    "subject_key_list = [subject_key_list[6*i] for i in range(3*n_subjects)]\n",
    "subject_item_list = [subject_item_list[6*i:6*(i + 1)] for i in range(3*n_subjects)]\n",
    "data_by_subject = dict(zip(subject_key_list, subject_item_list))\n",
    "\n",
    "group_key_list = []\n",
    "group_item_list = []\n",
    "for key, item in group_avg:\n",
    "    group_key_list.append(key)\n",
    "    group_item_list.append(item[\"correct\"].values.mean())\n",
    "group_key_list = [(row[0] + \"-\" + row[1]) for row in group_key_list]\n",
    "group_key_list = [group_key_list[6*i] for i in range(3)]\n",
    "group_item_list = [group_item_list[6*i:6*(i + 1)] for i in range(3)]\n",
    "group_data = dict(zip(group_key_list, group_item_list))\n",
    "\n",
    "# Set plot elements\n",
    "x_values = np.arange(5, 31, 5)\n",
    "\n",
    "subject_symbols = [\"s\", \"^\", \"v\", \"d\", \"*\", \"h\", \"X\", \"P\"]\n",
    "task_colors = [\"r\", \"b\", \"g\"]\n",
    "subj_markr_dict = dict(zip(subject_IDs, subject_symbols[:n_subjects]))\n",
    "task_color_dict = dict(zip(group_data.keys(), task_colors))\n",
    "\n",
    "legend_elements = [Patch(facecolor=\"r\", label=\"BUG-MD\"),\n",
    "                   Patch(facecolor=\"b\", label=\"SMN-MD\"),\n",
    "                   Patch(facecolor=\"g\", label=\"BUG-ID\")]\n",
    "\n",
    "# Make plot\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "\n",
    "# Lines indicating random guessing\n",
    "# ax.hlines(1/3, 3, 32, linestyle=\":\", color=\"m\", alpha=1)\n",
    "# ax.text(32.2, 1/3 - 0.01, \"Chance level (MD)\")\n",
    "# ax.hlines(1/8, 3, 32, linestyle=\":\", color=\"g\", alpha=1)\n",
    "# ax.text(32.2, 1/8 - 0.01, \"Chance level (ID)\")\n",
    "\n",
    "for task in task_color_dict.keys():\n",
    "    ax.plot(x_values, group_data[task],\n",
    "            linestyle=\"-\",\n",
    "            marker=\"o\",\n",
    "            markersize=\"6\",\n",
    "            color=task_color_dict[task])\n",
    "\n",
    "for subject in subject_IDs:\n",
    "    for task in task_color_dict.keys():\n",
    "        ax.scatter(x_values, data_by_subject[(subject, task)],\n",
    "                   s=48,\n",
    "                   marker=subj_markr_dict[subject],\n",
    "                   color=\"w\",\n",
    "                   edgecolor=task_color_dict[task],\n",
    "                   alpha=0.75)\n",
    "\n",
    "ax.set_xticks(np.arange(5, 31, 5))\n",
    "ax.set_xticklabels([r\"${:d}^\\circ$\".format(i) for i in np.arange(5, 31, 5)], fontsize=16)\n",
    "ax.set_xlim((3, 32))\n",
    "ax.set_xlabel(\"Target motion amplitude\", fontsize=20)\n",
    "\n",
    "ax.set_yticks(np.linspace(0.1, 0.9, 9, endpoint=True))\n",
    "ax.set_yticklabels([\"{:.1f}\".format(i) for i in np.linspace(0.1, 0.9, 9, endpoint=True)], fontsize=16)\n",
    "ax.set_ylim((0, 1))\n",
    "ax.set_ylabel(\"\\% correct\", fontsize=20)\n",
    "\n",
    "ax.grid(linestyle=\"-\", alpha=0.5)\n",
    "ax.legend(handles=legend_elements, fontsize=14, loc=2)\n",
    "\n",
    "plt.show()\n",
    "# plt.savefig(\"MSM_v1.1_data_individual.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_BUG_ID = only_target[only_target[\"task_type\"] == \"speech_ID\"]\n",
    "gb_BUG_ID = only_BUG_ID.groupby([\"subject_ID\", \"amplitude\"])\n",
    "\n",
    "key_list = []\n",
    "item_list = []\n",
    "for key, item in gb_BUG_ID:\n",
    "    key_list.append(key)\n",
    "    subj_responses = item[\"subj_response\"].values\n",
    "    n_trials = len(item[\"subj_response\"])\n",
    "    patterns = item[\"pattern\"].values\n",
    "    summed = sum([compare_answers(subj_responses[i], patterns[i])\n",
    "                  for i in range(len(subj_responses))])/n_trials\n",
    "    item_list.append(summed)\n",
    "#     print(key, summed)\n",
    "\n",
    "amp_list = [5., 10., 15., 20., 25., 30.]\n",
    "\n",
    "fig, axes = plt.subplots(n_subjects, 6, figsize=(18, 3*n_subjects))\n",
    "\n",
    "for i, row_ax in enumerate(axes):\n",
    "    for j, ax in enumerate(row_ax):\n",
    "        ax.set_xticks(np.arange(1, 6))\n",
    "        ax.set_yticks(np.linspace(0.1, 0.9, 9, endpoint=True))        \n",
    "        if i == 0:\n",
    "            ax.set_title(\"Target motion = ${:.0f}^\\circ$\".format(amp_list[j]), fontsize=16)\n",
    "        \n",
    "        if i == (n_subjects - 1):\n",
    "            ax.set_xticklabels([\"{:d}\".format(ii) for ii in np.arange(1, 6)], fontsize=12)\n",
    "        else:\n",
    "            ax.set_xticklabels(())\n",
    "        \n",
    "        if j == 0:\n",
    "            ax.set_yticklabels([\"{:.1f}\".format(ii) for ii in\n",
    "                                np.linspace(0.1, 0.9, 9, endpoint=True)], fontsize=12)\n",
    "            ax.set_ylabel(subject_IDs[i], fontsize=16)\n",
    "        else:\n",
    "            ax.set_yticklabels(())\n",
    "        \n",
    "        if i != (n_subjects - 1):\n",
    "            ax.tick_params(axis=\"x\", which=\"both\", top=False, bottom=False, labelbottom=True)\n",
    "        \n",
    "        if j != 0:\n",
    "            ax.tick_params(axis=\"y\", which=\"both\", left=False, right=False, labelleft=True)\n",
    "\n",
    "\n",
    "for i, key in enumerate(key_list):\n",
    "    curr_subj = key[0]\n",
    "    curr_amp  = key[1]\n",
    "    row = subject_IDs.index(curr_subj)\n",
    "    col = amp_list.index(curr_amp)\n",
    "    axes[row, col].bar(np.arange(1, 6), item_list[i], color=\"g\", alpha=0.75)\n",
    "    axes[row, col].set_xlim(0.25, 5.75)\n",
    "    axes[row, col].set_ylim(0, 1)\n",
    "    axes[row, col].grid(linestyle=\":\")\n",
    "\n",
    "plt.text(-16.25, -0.25, \"Word position\", fontsize=20)\n",
    "\n",
    "plt.show()\n",
    "# plt.savefig(\"MSM_v1.1_word_position_by_subject.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traditional confidence intervals with full pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_CI(task_df, CI_width=0.95):\n",
    "    from scipy.stats import norm\n",
    "    q = 0.5 + CI_width/2\n",
    "    z_alpha = norm.ppf(q)\n",
    "    n = task_df.groupby(\"amplitude\").count()[\"run_num\"].values[0]\n",
    "    task_df_group_p = task_df.groupby(\"amplitude\").mean()[\"correct\"].to_frame()\n",
    "    task_df_arcsin_group_p = 2/np.pi*np.arcsin(np.sqrt(task_df_group_p))\n",
    "    task_df_arcsin_se = z_alpha*np.sqrt(task_df_arcsin_group_p*(1 - task_df_arcsin_group_p)/n)\n",
    "    task_df_arcsin_group_p_lb = task_df_arcsin_group_p - task_df_arcsin_se\n",
    "    task_df_arcsin_group_p_ub = task_df_arcsin_group_p + task_df_arcsin_se\n",
    "    task_df_arcsin_CI = pd.concat([task_df_arcsin_group_p_lb,\n",
    "                                   task_df_arcsin_group_p,\n",
    "                                   task_df_arcsin_group_p_ub], axis=1)\n",
    "    task_df_arcsin_CI.columns = [\"CI_lb\", \"p\", \"CI_ub\"]\n",
    "    task_df_backtransform_CI = np.power(np.sin(np.pi/2*task_df_arcsin_CI), 2)\n",
    "    return task_df_backtransform_CI, task_df_arcsin_group_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a df consisting of only target rows\n",
    "MD_BUG = \\\n",
    "    all_runs_df[(all_runs_df[\"is_target\"]) &\n",
    "                (all_runs_df[\"stim_type\"] == \"BUG\") &\n",
    "                (all_runs_df[\"task_type\"] == \"motion_detection\")]\n",
    "MD_SMN = \\\n",
    "    all_runs_df[(all_runs_df[\"is_target\"]) &\n",
    "                (all_runs_df[\"stim_type\"] == \"SMN\") &\n",
    "                (all_runs_df[\"task_type\"] == \"motion_detection\")]\n",
    "SI_BUG = \\\n",
    "    all_runs_df[(all_runs_df[\"is_target\"]) &\n",
    "                (all_runs_df[\"stim_type\"] == \"BUG\") &\n",
    "                (all_runs_df[\"task_type\"] == \"speech_ID\")]\n",
    "MD_BUG_backtransform_CI95, MD_BUG_arcsin = compute_CI(MD_BUG)\n",
    "MD_SMN_backtransform_CI95, MD_SMN_arcsin = compute_CI(MD_SMN)\n",
    "SI_BUG_backtransform_CI95, SI_BUG_arcsin = compute_CI(SI_BUG)\n",
    "MD_BUG_arcsin.insert(0, \"task_type\", 6*[\"MD_BUG\"])\n",
    "MD_SMN_arcsin.insert(0, \"task_type\", 6*[\"MD_SMN\"])\n",
    "SI_BUG_arcsin.insert(0, \"task_type\", 6*[\"SI_BUG\"])\n",
    "group_arcsin_p_df = pd.concat([MD_BUG_arcsin, MD_SMN_arcsin, SI_BUG_arcsin]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"r\", \"b\", \"g\"]\n",
    "CI_container = [MD_BUG_backtransform_CI95,\n",
    "                MD_SMN_backtransform_CI95,\n",
    "                SI_BUG_backtransform_CI95]\n",
    "x = CI_container[0][\"p\"].index.values\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "ax.set_title(\"Per Task 95\\% Confidence Intervals (n={:d})\".format(n_subjects), fontsize=24)\n",
    "for i, CI in enumerate(CI_container):\n",
    "    p = CI[\"p\"].values\n",
    "    p_err = CI.loc[:, (\"CI_lb\", \"CI_ub\")].values\n",
    "    p_err[:, 0] = p - p_err[:, 0]\n",
    "    p_err[:, 1] = p_err[:, 1] - p\n",
    "    ax.errorbar(x + 1.25*(i - 1), p, yerr=p_err.T, fmt=\"-o\", color=colors[i])\n",
    "\n",
    "ax.set_xticks(np.linspace(5, 30, 6))\n",
    "ax.set_xticklabels([r\"${:d}^\\circ$\".format(int(i)) for i in np.linspace(5, 30, 6)], fontsize=14)\n",
    "ax.set_xlabel(\"Target motion amplitude\", fontsize=16)\n",
    "ax.set_ylim((0, 1))\n",
    "ax.set_yticks(np.linspace(0.1, 0.9, 9))\n",
    "ax.set_yticklabels([\"{:.1f}\".format(f) for f in np.linspace(0.1, 0.9, 9)], fontsize=14)\n",
    "ax.set_ylabel(\"Proportion correct\", fontsize=16)\n",
    "ax.grid(\":\")\n",
    "ax.legend((r\"MD-BUG\", r\"MD-SMN\", r\"SI-BUG\"), loc=2, fontsize=16)\n",
    "\n",
    "plt.show()\n",
    "# plt.savefig(\"MSM_v1.1_CI95.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RM-ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.anova import AnovaRM\n",
    "\n",
    "rmanova_fit = AnovaRM(data=group_arcsin_p_df,\n",
    "                      depvar=\"correct\",\n",
    "                      subject=\"task_type\",\n",
    "                      within=[\"amplitude\"]).fit()\n",
    "print(rmanova_fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get CI for speech ID broken down by word position and motion amplitude\n",
    "* Still averaged across subjects (group means)\n",
    "* Here n=60 per point for 5 subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SI_BUG_gb = SI_BUG.groupby([\"amplitude\"])\n",
    "n_SI_by_word = SI_BUG_gb.count()[\"run_num\"].values[0]\n",
    "\n",
    "key_list = []\n",
    "item_list = []\n",
    "for key, item in SI_BUG_gb:\n",
    "    key_list.append(key)\n",
    "    subj_responses = item[\"subj_response\"].values\n",
    "    patterns = item[\"pattern\"].values\n",
    "    summed = sum([compare_answers(subj_responses[i], patterns[i])\n",
    "                  for i in range(len(subj_responses))])/n_SI_by_word\n",
    "    item_list.append(summed)\n",
    "\n",
    "dummy = []\n",
    "for i in range(len(key_list)):\n",
    "    dummy.append([key_list[i]] + item_list[i].tolist())\n",
    "SI_by_word_position = pd.DataFrame(dummy, columns=(\"amplitude\", 1, 2, 3, 4, 5))\n",
    "\n",
    "\n",
    "\n",
    "# fig, axes = plt.subplots(1, len(SI_by_word_position), figsize=(3*len(SI_by_word_position), 3))\n",
    "\n",
    "# x = np.array([1., 2., 3., 4., 5.])\n",
    "# z_alpha = 1.96\n",
    "# n = 60\n",
    "\n",
    "# for i in range(len(SI_by_word_position)):\n",
    "#     curr_SI_p = SI_by_word_position.loc[i][1:6].values\n",
    "#     curr_SI_p_arcsin = 2/np.pi*np.arcsin(np.sqrt(curr_SI_p))\n",
    "#     curr_SI_p_arcsin_se = z_alpha*np.sqrt(curr_SI_p_arcsin*(1 - curr_SI_p_arcsin)/n)\n",
    "#     curr_SI_p_arcsin_lb = curr_SI_p_arcsin - curr_SI_p_arcsin_se\n",
    "#     curr_SI_p_arcsin_ub = curr_SI_p_arcsin + curr_SI_p_arcsin_se\n",
    "#     curr_SI_p_lb = np.power(np.sin(np.pi/2*curr_SI_p_arcsin_lb), 2)\n",
    "#     curr_SI_p_ub = np.power(np.sin(np.pi/2*curr_SI_p_arcsin_ub), 2)\n",
    "#     curr_SI_p_se_lb = curr_SI_p - curr_SI_p_lb\n",
    "#     curr_SI_p_se_ub = curr_SI_p_ub - curr_SI_p\n",
    "#     p_err = np.concatenate([curr_SI_p_se_lb, curr_SI_p_se_ub])\n",
    "    \n",
    "# #     axes[i].errorbar(x, curr_SI_p, yerr=p_err, fmt=\"-o\", color=\"g\")\n",
    "#     axes[i].plot(x, curr_SI_p)\n",
    "#     axes[i].plot(x, curr_SI_p_lb, \"--\")\n",
    "#     axes[i].plot(x, curr_SI_p_ub, \":\")\n",
    "#     axes[i].set_ylim((0, 1))\n",
    "#     axes[i].grid(\":\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, len(SI_by_word_position), figsize=(3*len(SI_by_word_position), 3))\n",
    "\n",
    "x = np.array([1., 2., 3., 4., 5.])\n",
    "for i, row in SI_by_word_position.iterrows():\n",
    "    y = row[x].values\n",
    "    axes[i].plot(x, y, \"go-\")\n",
    "    \n",
    "    axes[i].set_title(r\"Target motion = ${:d}^\\circ$\".format(int(row[\"amplitude\"])), fontsize=16)\n",
    "    axes[i].set_xticks(np.arange(1, 6))\n",
    "    axes[i].set_xticklabels([\"{:d}\".format(d) for d in np.arange(1, 6)], fontsize=14)\n",
    "    axes[i].set_yticks(np.linspace(0.1, 0.7, 8))\n",
    "    if i != 0:\n",
    "        axes[i].set_yticklabels(())\n",
    "    else:\n",
    "        axes[i].set_yticklabels([\"{:.1f}\".format(f) for f in np.linspace(0.1, 0.7, 8)], fontsize=14)\n",
    "        axes[i].set_ylabel(\"Proportion correct\", fontsize=16)\n",
    "    axes[i].set_ylim((0.05, 0.75))\n",
    "    axes[i].grid(\":\")\n",
    "fig.text(0.475, -0.05, \"Word position\", fontsize=16)\n",
    "\n",
    "plt.show()\n",
    "# plt.savefig(\"MSM_v1.1_group_word_position.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look for position effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MD_BUG_L = \\\n",
    "    all_runs_df[(all_runs_df[\"is_target\"]) &\n",
    "                (all_runs_df[\"stim_type\"] == \"BUG\") &\n",
    "                (all_runs_df[\"task_type\"] == \"motion_detection\") &\n",
    "                (all_runs_df[\"init_angle\"] == -40)].reset_index(drop=True)\n",
    "MD_BUG_C = \\\n",
    "    all_runs_df[(all_runs_df[\"is_target\"]) &\n",
    "                (all_runs_df[\"stim_type\"] == \"BUG\") &\n",
    "                (all_runs_df[\"task_type\"] == \"motion_detection\") &\n",
    "                (all_runs_df[\"init_angle\"] == 0)].reset_index(drop=True)\n",
    "MD_BUG_R = \\\n",
    "    all_runs_df[(all_runs_df[\"is_target\"]) &\n",
    "                (all_runs_df[\"stim_type\"] == \"BUG\") &\n",
    "                (all_runs_df[\"task_type\"] == \"motion_detection\") &\n",
    "                (all_runs_df[\"init_angle\"] == 40)].reset_index(drop=True)\n",
    "MD_SMN_L = \\\n",
    "    all_runs_df[(all_runs_df[\"is_target\"]) &\n",
    "                (all_runs_df[\"stim_type\"] == \"SMN\") &\n",
    "                (all_runs_df[\"task_type\"] == \"motion_detection\") &\n",
    "                (all_runs_df[\"init_angle\"] == -40)].reset_index(drop=True)\n",
    "MD_SMN_C = \\\n",
    "    all_runs_df[(all_runs_df[\"is_target\"]) &\n",
    "                (all_runs_df[\"stim_type\"] == \"SMN\") &\n",
    "                (all_runs_df[\"task_type\"] == \"motion_detection\") &\n",
    "                (all_runs_df[\"init_angle\"] == 0)].reset_index(drop=True)\n",
    "MD_SMN_R = \\\n",
    "    all_runs_df[(all_runs_df[\"is_target\"]) &\n",
    "                (all_runs_df[\"stim_type\"] == \"SMN\") &\n",
    "                (all_runs_df[\"task_type\"] == \"motion_detection\") &\n",
    "                (all_runs_df[\"init_angle\"] == 40)].reset_index(drop=True)\n",
    "SI_BUG_L = \\\n",
    "    all_runs_df[(all_runs_df[\"is_target\"]) &\n",
    "                (all_runs_df[\"stim_type\"] == \"BUG\") &\n",
    "                (all_runs_df[\"task_type\"] == \"speech_ID\") &\n",
    "                (all_runs_df[\"init_angle\"] == -40)].reset_index(drop=True)\n",
    "SI_BUG_C = \\\n",
    "    all_runs_df[(all_runs_df[\"is_target\"]) &\n",
    "                (all_runs_df[\"stim_type\"] == \"BUG\") &\n",
    "                (all_runs_df[\"task_type\"] == \"speech_ID\") &\n",
    "                (all_runs_df[\"init_angle\"] == 0)].reset_index(drop=True)\n",
    "SI_BUG_R = \\\n",
    "    all_runs_df[(all_runs_df[\"is_target\"]) &\n",
    "                (all_runs_df[\"stim_type\"] == \"BUG\") &\n",
    "                (all_runs_df[\"task_type\"] == \"speech_ID\") &\n",
    "                (all_runs_df[\"init_angle\"] == 40)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitudes = sorted(list(set(MD_BUG_L[\"amplitude\"].values)))\n",
    "\n",
    "MD_BUG_L_corr = MD_BUG_L.groupby([\"amplitude\"]).mean()[\"correct\"].values\n",
    "MD_BUG_C_corr = MD_BUG_C.groupby([\"amplitude\"]).mean()[\"correct\"].values\n",
    "MD_BUG_R_corr = MD_BUG_R.groupby([\"amplitude\"]).mean()[\"correct\"].values\n",
    "\n",
    "MD_SMN_L_corr = MD_SMN_L.groupby([\"amplitude\"]).mean()[\"correct\"].values\n",
    "MD_SMN_C_corr = MD_SMN_C.groupby([\"amplitude\"]).mean()[\"correct\"].values\n",
    "MD_SMN_R_corr = MD_SMN_R.groupby([\"amplitude\"]).mean()[\"correct\"].values\n",
    "\n",
    "SI_BUG_L_corr = SI_BUG_L.groupby([\"amplitude\"]).mean()[\"correct\"].values\n",
    "SI_BUG_C_corr = SI_BUG_C.groupby([\"amplitude\"]).mean()[\"correct\"].values\n",
    "SI_BUG_R_corr = SI_BUG_R.groupby([\"amplitude\"]).mean()[\"correct\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, len(amplitudes), figsize=(3*len(amplitudes), 10))\n",
    "\n",
    "for i, amp in enumerate(amplitudes):\n",
    "    axes[0, i].bar(-1, MD_BUG_L_corr[i], color=\"b\")\n",
    "    axes[0, i].bar( 0, MD_BUG_C_corr[i], color=\"g\")\n",
    "    axes[0, i].bar( 1, MD_BUG_R_corr[i], color=\"r\")\n",
    "    axes[0, i].set_xticks((-1, 0, 1))\n",
    "    axes[0, i].set_xticklabels([\"$-40^\\circ$\", \"$0^\\circ$\", \"$40^\\circ$\"])\n",
    "    axes[0, i].set_yticks(np.linspace(0.1, 0.9, 9))\n",
    "    axes[0, i].set_yticklabels([\"{:.1f}\".format(num) for num in np.linspace(0.1, 0.9, 9)])\n",
    "    axes[0, i].set_ylim((0, 1))\n",
    "    axes[0, i].grid(\":\", alpha=0.5)\n",
    "\n",
    "    axes[1, i].bar(-1, MD_SMN_L_corr[i], color=\"b\")\n",
    "    axes[1, i].bar( 0, MD_SMN_C_corr[i], color=\"g\")\n",
    "    axes[1, i].bar( 1, MD_SMN_R_corr[i], color=\"r\")\n",
    "    axes[1, i].set_xticks((-1, 0, 1))\n",
    "    axes[1, i].set_xticklabels([\"$-40^\\circ$\", \"$0^\\circ$\", \"$40^\\circ$\"])\n",
    "    axes[1, i].set_yticks(np.linspace(0.1, 0.9, 9))\n",
    "    axes[1, i].set_yticklabels([\"{:.1f}\".format(num) for num in np.linspace(0.1, 0.9, 9)])\n",
    "    axes[1, i].set_ylim((0, 1))\n",
    "    axes[1, i].grid(\":\", alpha=0.5)\n",
    "    \n",
    "    axes[2, i].bar(-1, SI_BUG_L_corr[i], color=\"b\")\n",
    "    axes[2, i].bar( 0, SI_BUG_C_corr[i], color=\"g\")\n",
    "    axes[2, i].bar( 1, SI_BUG_R_corr[i], color=\"r\")\n",
    "    axes[2, i].set_xticks((-1, 0, 1))\n",
    "    axes[2, i].set_xticklabels([\"$-40^\\circ$\", \"$0^\\circ$\", \"$40^\\circ$\"])\n",
    "    axes[2, i].set_yticks(np.linspace(0.1, 0.9, 9))\n",
    "    axes[2, i].set_yticklabels([\"{:.1f}\".format(num) for num in np.linspace(0.1, 0.9, 9)])\n",
    "    axes[2, i].set_ylim((0, 1))\n",
    "    axes[2, i].grid(\":\", alpha=0.5)\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(6):\n",
    "        if i == 0:\n",
    "            axes[i, j].set_title(\"Target motion = {:d}$^\\circ$\".format(int(amplitudes[j])))\n",
    "        if i != 2:\n",
    "            axes[i, j].set_xticklabels(())\n",
    "        if j == 0:\n",
    "            axes[0, j].set_ylabel(\"MD-BUG\", fontsize=16)\n",
    "            axes[1, j].set_ylabel(\"MD-SMN\", fontsize=16)\n",
    "            axes[2, j].set_ylabel(\"SI-BUG\", fontsize=16)\n",
    "        if j != 0:\n",
    "            axes[i, j].set_yticklabels(())\n",
    "\n",
    "fig.text(0.45, 0.075, \"Target position\", fontsize=\"16\")\n",
    "\n",
    "plt.show()\n",
    "# plt.savefig(\"MSM_v1.1_position_effect.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_ID = all_runs_df[(all_runs_df[\"stim_type\"] == \"BUG\") &\n",
    "                        (all_runs_df[\"task_type\"] == \"speech_ID\")].reset_index(drop=True)\n",
    "\n",
    "total_possible_score = int(len(speech_ID)/3*5/6)\n",
    "target_stream_by_amp = {5.:0, 10.:0, 15.:0, 20.:0, 25.:0, 30.:0}\n",
    "masker_stream_by_amp = {5.:0, 10.:0, 15.:0, 20.:0, 25.:0, 30.:0}\n",
    "for i in range(0, len(speech_ID), 3):\n",
    "    curr_trial = speech_ID.loc[i:i + 2]\n",
    "    target_idx  = np.argwhere(curr_trial[\"is_target\"].values)[0][0]\n",
    "    masker_idxs = sorted(list(set(range(3)) - set([target_idx])))\n",
    "    curr_amp = curr_trial.iloc[target_idx][\"amplitude\"]\n",
    "    subj_response = curr_trial[\"subj_response\"].values[0]\n",
    "    talker_sentences = [row[1][\"pattern\"] for\n",
    "                        row in curr_trial.iterrows()]\n",
    "    target_stream_by_amp[curr_amp] += sum(compare_answers(subj_response, talker_sentences[target_idx]))\n",
    "    masker_stream_by_amp[curr_amp] += sum(compare_answers(subj_response, talker_sentences[masker_idxs[0]]) + \\\n",
    "                                          compare_answers(subj_response, talker_sentences[masker_idxs[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_stream_prop = np.array(list(target_stream_by_amp.values()))/total_possible_score\n",
    "masker_stream_prop = np.array(list(masker_stream_by_amp.values()))/total_possible_score\n",
    "neither_stream_prop = np.ones(target_stream_prop.size) - target_stream_prop - masker_stream_prop\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "\n",
    "ax.set_title(\"Error source plot\", fontsize=24)\n",
    "\n",
    "ax.bar(amplitudes, target_stream_prop, width=3, label=\"Target stream\")\n",
    "ax.bar(amplitudes, masker_stream_prop, width=3, bottom=target_stream_prop, label=\"Masker stream\")\n",
    "ax.bar(amplitudes, neither_stream_prop, width=3, bottom=target_stream_prop + masker_stream_prop, label=\"Random error\")\n",
    "\n",
    "ax.set_xlabel(\"Target motion range\", fontsize=18)\n",
    "ax.set_xticks(amplitudes)\n",
    "ax.set_xticklabels([\"{:d}$^\\circ$\".format(int(amp)) for amp in amplitudes], fontsize=16)\n",
    "\n",
    "ax.set_yticks(np.linspace(0.1, 1, 10))\n",
    "ax.set_yticklabels([\"{:.1f}\".format(num) for num in np.linspace(0.1, 1, 10)], fontsize=16)\n",
    "\n",
    "ax.legend(fontsize=16, loc=4)\n",
    "ax.grid(\":\", alpha=0.75)\n",
    "\n",
    "plt.show()\n",
    "# plt.savefig(\"MSM_v1.1_error_source.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More detailed error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stream_idx(subj_response, streams):\n",
    "    \"Return the stream index for each word in subject response\"\n",
    "    container = []\n",
    "    for i, word in enumerate(subj_response.split()):\n",
    "        curr_pos_words = [streams[j].split()[i] for j in range(len(streams))]\n",
    "        try:\n",
    "            curr_word_idx = curr_pos_words.index(word)\n",
    "        except ValueError:\n",
    "            curr_word_idx = 1j\n",
    "        container.append(curr_word_idx)\n",
    "    return np.array(container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_ID = all_runs_df[(all_runs_df[\"stim_type\"] == \"BUG\") &\n",
    "                        (all_runs_df[\"task_type\"] == \"speech_ID\")].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    3,    6, ..., 5391, 5394, 5397])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0, 5400, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5400"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speech_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "zdx = 12\n",
    "curr_trial = speech_ID.loc[zdx:zdx + 2]\n",
    "target_idx = curr_trial[\"is_target\"]\n",
    "subj_response = curr_trial[\"subj_response\"].values[0]\n",
    "streams = list(curr_trial[\"pattern\"].values)\n",
    "stream_idx = get_stream_idx(subj_response, streams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.+1.j, 0.+1.j, 2.+0.j, 0.+0.j, 1.+0.j])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(stream_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.diff(stream_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_ID = all_runs_df[(all_runs_df[\"stim_type\"] == \"BUG\") &\n",
    "                        (all_runs_df[\"task_type\"] == \"speech_ID\")].reset_index()\n",
    "\n",
    "total_possible_score = int(len(speech_ID)/3*5/6)\n",
    "target_stream_by_amp = {5.:0, 10.:0, 15.:0, 20.:0, 25.:0, 30.:0}\n",
    "masker_stream_by_amp = {5.:0, 10.:0, 15.:0, 20.:0, 25.:0, 30.:0}\n",
    "for i in range(0, len(speech_ID), 3):\n",
    "    curr_trial = speech_ID.loc[i:i + 2]\n",
    "    target_idx  = np.argwhere(curr_trial[\"is_target\"].values)[0][0]\n",
    "    masker_idxs = sorted(list(set(range(3)) - set([target_idx])))\n",
    "    curr_amp = curr_trial.iloc[target_idx][\"amplitude\"]\n",
    "    subj_response = curr_trial[\"subj_response\"].values[0]\n",
    "    talker_sentences = [row[1][\"pattern\"] for\n",
    "                        row in curr_trial.iterrows()]\n",
    "    target_stream_by_amp[curr_amp] += sum(compare_answers(subj_response, talker_sentences[target_idx]))\n",
    "    masker_stream_by_amp[curr_amp] += sum(compare_answers(subj_response, talker_sentences[masker_idxs[0]]) + \\\n",
    "                                          compare_answers(subj_response, talker_sentences[masker_idxs[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUG_MD_only_target = \\\n",
    "    all_runs_df[(all_runs_df[\"stim_type\"] == \"BUG\") &\n",
    "                (all_runs_df[\"task_type\"] == \"motion_detection\") &\n",
    "                (all_runs_df[\"is_target\"]) & \n",
    "                (all_runs_df[\"block_num\"] != \"P1\") &\n",
    "                (all_runs_df[\"block_num\"] != \"P2\") &\n",
    "                (all_runs_df[\"block_num\"] != \"P3\")]\n",
    "amps = BUG_MD_only_target[\"amplitude\"].values\n",
    "X = amps.reshape(len(amps), 1)\n",
    "# X = np.stack((np.ones(amps.shape), amps)).T\n",
    "Y = BUG_MD_only_target[\"correct\"].values.astype(int)\n",
    "\n",
    "n_features = X.shape[1]\n",
    "with pm.Model() as BUG_MD_model:\n",
    "    beta = pm.Normal(\"beta\", 0, 10, shape=n_features)\n",
    "    pred = tt.sum(X*beta, axis=1)\n",
    "    likelihood = pm.Bernoulli(\"y\", pm.math.invlogit(pred), observed=Y)\n",
    "    \n",
    "    trace = pm.sample(5000, chains=2, target_accept=0.9, return_inferencedata=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with BUG_MD_model:\n",
    "    print(pm.summary(trace))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with BUG_MD_model:\n",
    "    az.plot_trace(trace)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with BUG_MD_model:\n",
    "    az.plot_autocorr(trace)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with BUG_MD_model:\n",
    "    az.plot_forest(trace)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pilot v8.2\n",
    "### 06/17/21\n",
    "\n",
    "* Score according to amplitude and task_type\n",
    "* Score according to position and task_type\n",
    "* Score according to word position and task_type\n",
    "* Different symbols for different listeners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_target_df = all_runs_df[all_runs_df[\"is_target\"]]\n",
    "\n",
    "# task_type_order = [\"motion_detection\", \"speech_intelligibility\"]\n",
    "# task_type_order = [\"motion_detection\"]\n",
    "stim_type_order = [\"SMN\", \"BUG\"]\n",
    "listener_order = [\"DC\", \"AYC\"]\n",
    "colors = [\"b\", \"r\"]\n",
    "symbols = [\"s\", \"^\"]\n",
    "lines = [\":\", \"-.\"]\n",
    "# listener_order = [\"L452\", \"L469\"]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "\n",
    "for i, stim_type in enumerate(stim_type_order):\n",
    "# for task_type in task_type_order:\n",
    "    curr_task_df = only_target_df[only_target_df[\"stim_type\"] == stim_type]\n",
    "    curr_amplitudes = sorted(list(set(curr_task_df[\"amplitude\"].values)))\n",
    "    for j, listener in enumerate(listener_order):\n",
    "        curr_listener_df = curr_task_df[curr_task_df[\"subject_ID\"] == listener]\n",
    "        if task_type == \"motion_detection\":\n",
    "            grouped_by_amp = curr_listener_df.groupby(\"amplitude\").mean()\n",
    "            corr = grouped_by_amp[\"correct\"].values\n",
    "            \n",
    "            ax.plot(curr_amplitudes, corr, colors[i] + symbols[j] + lines[i], alpha=0.75, markersize=12)\n",
    "\n",
    "ax.set_xlabel(\"Target oscillation amplitude [deg]\", fontsize=18)\n",
    "ax.set_ylim((0, 1))\n",
    "ax.set_yticks(np.arange(0, 1.01, 0.1))\n",
    "ax.set_ylabel(\"Proportion correct\", fontsize=18)\n",
    "ax.grid(linestyle=\":\")\n",
    "ax.legend((\"SMN-DC\", \"SMN-AYC\", \"BUG-DC\", \"BUG-AYC\"), fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_amp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pilot v8.1\n",
    "### 06/17/21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_ID = all_runs_df[(all_runs_df[\"is_target\"]) &\n",
    "                        (all_runs_df[\"task_type\"] == \"speech_intelligibility\")].drop(\\\n",
    "                columns=[\"n_src\", \"src\", \"task_type\", \"elapsed_time\", \"rate\", \"run_num\", \"block_num\",\n",
    "                         \"trial_num\", \"stim_num\", \"is_target\"])\n",
    "speech_ID = speech_ID.reset_index(drop=True)\n",
    "\n",
    "\n",
    "subjs = [\"L469\", \"L452\"]\n",
    "amps = [0.0, 1.25, 5.0, 15.0, 20.0, 30.0]\n",
    "data_dict = {}\n",
    "for subj in subjs:\n",
    "    for amp in amps:\n",
    "        curr_corr = speech_ID[(speech_ID[\"subject_ID\"] == subj) &\n",
    "                              (speech_ID[\"amplitude\"] == amp)][\"correct\"].values\n",
    "        curr_n_trials = len(curr_corr)\n",
    "        curr_corr_prop = sum(curr_corr)/(5*curr_n_trials)\n",
    "        \n",
    "        data_dict[(subj, amp)] = (curr_n_trials, curr_corr_prop)\n",
    "\n",
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"r\", \"b\"]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "\n",
    "for i, subj in enumerate(subjs):\n",
    "    curr_subj_prop = []\n",
    "    curr_n_trials = []\n",
    "    for amp in amps:\n",
    "        curr_n_trials.append(data_dict[(subj, amp)][0])\n",
    "        curr_subj_prop.append(data_dict[(subj, amp)][1])\n",
    "    curr_marker_sizes = np.array(curr_n_trials)\n",
    "    curr_marker_sizes = 80*curr_marker_sizes/curr_marker_sizes.max()\n",
    "    ax.plot(amps, curr_subj_prop, colors[i] + \"--\", alpha=0.75)\n",
    "    ax.scatter(amps, curr_subj_prop, s=curr_marker_sizes, c=colors[i])\n",
    "\n",
    "ax.set_title(\"Speech ID performance\", fontsize=24)\n",
    "ax.set_xlabel(\"Target motion range [deg]\", fontsize=20)\n",
    "ax.set_ylabel(\"Proportion correct\", fontsize=20)\n",
    "\n",
    "ax.set_xticks(np.arange(0, 31, 5))\n",
    "ax.set_xticklabels([\"{:d}\".format(i) for i in np.arange(0, 31, 5)], fontsize=16)\n",
    "ax.set_yticks(np.linspace(0, 1, 11))\n",
    "ax.set_yticklabels([\"{:.1f}\".format(i) for i in np.linspace(0, 1, 11)], fontsize=16)\n",
    "\n",
    "ax.grid(linestyle=\":\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pilot v7.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "color_dict = {2: \"b\", 3: \"y\", 4: \"r\"}\n",
    "x_pos_dict = {0.0: 0, 1.25: 1, 5.: 2, 15.: 3, 20.: 4, 30.:5}\n",
    "x_ticks = np.array(list(x_pos_dict.values())) - 1.5\n",
    "x_ticklabels = [r\"$0^{\\circ}$\",\n",
    "                r\"$2.5^{\\circ}$\",\n",
    "                r\"$10^{\\circ}$\",\n",
    "                r\"$30^{\\circ}$\",\n",
    "                r\"$40^{\\circ}$\",\n",
    "                r\"$60^{\\circ}$\"]\n",
    "y_ticks = np.linspace(0.1, 0.9, 9)\n",
    "legend0 = []\n",
    "legend0.append(Patch(facecolor=\"b\", edgecolor=\"b\", label=\"2 talkers\", alpha=0.7))\n",
    "legend0.append(Patch(facecolor=\"y\", edgecolor=\"y\", label=\"3 talkers\", alpha=0.7))\n",
    "legend0.append(Patch(facecolor=\"r\", edgecolor=\"r\", label=\"4 talkers\", alpha=0.7))\n",
    "\n",
    "for row in prop_corr_df.iterrows():\n",
    "    curr_n_src = int(row[1][0])\n",
    "    curr_amp  = row[1][1]\n",
    "    curr_prop = row[1][2]\n",
    "    x_pos = (x_pos_dict[curr_amp] - 1.5) + 0.25*(curr_n_src - 3)\n",
    "    ax.bar(x_pos, curr_prop, align=\"center\", width=0.2, alpha=0.7, color=color_dict[curr_n_src])\n",
    "for curr_n_src in color_dict.keys():\n",
    "    curr_src_df = prop_corr_df[prop_corr_df[\"n_src\"] == curr_n_src]\n",
    "    x = np.arange(len(x_pos_dict)) - 1.5 + 0.25*(curr_n_src - 3)\n",
    "    y = curr_src_df[\"prop_corr\"].values\n",
    "    ax.plot(x, y, alpha=0.9, linestyle=\"--\", linewidth=1.5, color=color_dict[curr_n_src],\n",
    "                 marker=\"o\", markersize=14,\n",
    "                 markeredgecolor=\"k\", markeredgewidth=2,\n",
    "                 markerfacecolor=color_dict[curr_n_src])\n",
    "ax.set_title(\"Speech intelligibility as a function of N talkers and movement range\", fontsize=20)\n",
    "ax.set_xticks(x_ticks)\n",
    "ax.set_xticklabels(x_ticklabels, fontsize=16)\n",
    "ax.set_xlabel(\"Target movement range\", fontsize=18)\n",
    "ax.set_xlim((-2, 4))\n",
    "ax.set_yticks(y_ticks)\n",
    "ax.set_yticklabels((\"{:.1f}\".format(i) for i in y_ticks), fontsize=16)\n",
    "ax.set_ylabel(\"Proportion correct\", fontsize=18)\n",
    "ax.set_ylim((0, 1))\n",
    "ax.grid(linestyle=\":\", alpha=1)\n",
    "ax.legend(handles=legend0, loc=2, fontsize=16)\n",
    "\n",
    "plt.show()\n",
    "# plt.savefig(\"a.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pilot v7.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot as a function of rate and n_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_corr_series = cleaned_df.groupby([\"n_src\", \"amplitude\"]).mean()[\"correct\"]/5\n",
    "prop_corr_df = prop_corr_series.to_frame()\n",
    "prop_corr_df = prop_corr_df.stack().reset_index()\n",
    "prop_corr_df = prop_corr_df.drop(columns=\"level_2\")\n",
    "prop_corr_df.columns = [\"n_src\", \"amplitude\", \"prop_corr\"]\n",
    "\n",
    "adj_corr = []\n",
    "for row in prop_corr_df.iterrows():\n",
    "    curr_src = row[1][0]\n",
    "    curr_corr = row[1][2]\n",
    "    adj_corr.append(curr_corr - 1/curr_src)\n",
    "prop_corr_df.insert(len(prop_corr_df.columns), \"adj_corr\", adj_corr)\n",
    "adj_corr_df = prop_corr_df[prop_corr_df[\"amplitude\"] != 0.0]\n",
    "adj_corr_df = adj_corr_df.drop(columns=\"prop_corr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "fig.suptitle(\"Speech intelligibility as a function of N talkers and movement range\", fontsize=30)\n",
    "\n",
    "### Subplot 0\n",
    "color_dict = {2: \"b\", 3: \"y\", 4: \"r\"}\n",
    "x_pos_dict = {0.0: 0, 1.25: 1, 5.: 2, 15.: 3, 20.: 4, 30.:5}\n",
    "# x_pos_dict = {0.0: 0, 1.25: 1, 5.: 2, 20.: 3}\n",
    "# x_pos_dict = {0.0: 0, 15.: 1, 30.: 2}\n",
    "x_ticks = np.array(list(x_pos_dict.values())) - 1.5\n",
    "x_ticklabels = [r\"$0^{\\circ}$\",\n",
    "                r\"$2.5^{\\circ}$\",\n",
    "                r\"$10^{\\circ}$\",\n",
    "                r\"$30^{\\circ}$\",\n",
    "                r\"$40^{\\circ}$\",\n",
    "                r\"$60^{\\circ}$\"]\n",
    "# x_ticklabels = [r\"$0^{\\circ}$\",\n",
    "#                 r\"$2.5^{\\circ}$\",\n",
    "#                 r\"$10^{\\circ}$\",\n",
    "#                 r\"$40^{\\circ}$\"]\n",
    "# x_ticklabels = [r\"$0^{\\circ}$\",\n",
    "#                 r\"$15^{\\circ}$\",\n",
    "#                 r\"$30^{\\circ}$\"]\n",
    "y_ticks = np.linspace(0.1, 0.9, 9)\n",
    "legend0 = []\n",
    "legend0.append(Patch(facecolor=\"b\", edgecolor=\"b\", label=\"2 talkers\", alpha=0.7))\n",
    "legend0.append(Patch(facecolor=\"y\", edgecolor=\"y\", label=\"3 talkers\", alpha=0.7))\n",
    "legend0.append(Patch(facecolor=\"r\", edgecolor=\"r\", label=\"4 talkers\", alpha=0.7))\n",
    "# legend0.append(Line2D([], [], linestyle=\"\", marker=\"d\", markeredgewidth=1.5,\n",
    "#                       markeredgecolor=\"k\", markerfacecolor=\"w\", markersize=12,\n",
    "#                       label=\"Noise masker\"))\n",
    "# legend0.append(Line2D([], [], linestyle=\"\", marker=\"s\", markeredgewidth=1.5,\n",
    "#                       markeredgecolor=\"k\", markerfacecolor=\"w\", markersize=12,\n",
    "#                       label=\"Speech masker\"))\n",
    "# legend0.append(Line2D([], [], linestyle=\"\", marker=\"^\", markeredgewidth=1.5,\n",
    "#                       markeredgecolor=\"k\", markerfacecolor=\"k\", markersize=12,\n",
    "#                       label=r\"$\\pm 90^{\\circ}$\"))\n",
    "\n",
    "for row in prop_corr_df.iterrows():\n",
    "    curr_n_src = int(row[1][0])\n",
    "    curr_amp  = row[1][1]\n",
    "    curr_prop = row[1][2]\n",
    "    x_pos = (x_pos_dict[curr_amp] - 1.5) + 0.25*(curr_n_src - 3)\n",
    "    axes[0].bar(x_pos, curr_prop, align=\"center\", width=0.2, alpha=0.7, color=color_dict[curr_n_src])\n",
    "for curr_n_src in color_dict.keys():\n",
    "    curr_src_df = prop_corr_df[prop_corr_df[\"n_src\"] == curr_n_src]\n",
    "    x = np.arange(len(x_pos_dict)) - 1.5 + 0.25*(curr_n_src - 3)\n",
    "    y = curr_src_df[\"prop_corr\"].values\n",
    "    axes[0].plot(x, y, alpha=0.9, linestyle=\"--\", linewidth=1.5, color=color_dict[curr_n_src],\n",
    "                 marker=\"o\", markersize=14,\n",
    "                 markeredgecolor=\"k\", markeredgewidth=2,\n",
    "                 markerfacecolor=color_dict[curr_n_src])\n",
    "# axes[0].hlines([1/2, 1/3, 1/4], -2, 2, linestyle=\":\",\n",
    "#                colors=[\"b\", \"y\", \"r\"])\n",
    "axes[0].set_title(\"Raw proportions correct\", fontsize=20)\n",
    "axes[0].set_xticks(x_ticks)\n",
    "axes[0].set_xticklabels(x_ticklabels, fontsize=16)\n",
    "axes[0].set_xlim((-2, 4))\n",
    "axes[0].set_yticks(y_ticks)\n",
    "axes[0].set_yticklabels((\"{:.1f}\".format(i) for i in y_ticks), fontsize=16)\n",
    "axes[0].set_ylabel(\"Proportion correct\", fontsize=18)\n",
    "axes[0].set_ylim((0, 1))\n",
    "axes[0].grid(linestyle=\":\", alpha=1)\n",
    "axes[0].legend(handles=legend0, loc=2, fontsize=16)\n",
    "\n",
    "### Subplot 1\n",
    "x_pos_dict = {1.25: 0, 5.: 1, 20.: 2}\n",
    "# x_ticks = np.array(list(x_pos_dict.values())) - 1\n",
    "# x_ticklabels = [r\"$2.5^{\\circ}$\",\n",
    "#                 r\"$10^{\\circ}$\",\n",
    "#                 r\"$40^{\\circ}$\"]\n",
    "# y_ticks = np.linspace(0.1, 0.8, 8)\n",
    "\n",
    "# for row in adj_corr_df.iterrows():\n",
    "#     curr_n_src = int(row[1][0])\n",
    "#     curr_amp  = row[1][1]\n",
    "#     curr_prop = row[1][2]\n",
    "#     x_pos = (x_pos_dict[curr_amp] - 1) + 0.25*(curr_n_src - 3)\n",
    "#     axes[1].bar(x_pos, curr_prop, align=\"center\", width=0.2, alpha=0.75, color=color_dict[curr_n_src])\n",
    "# for curr_n_src in color_dict.keys():\n",
    "#     curr_src_df = adj_corr_df[adj_corr_df[\"n_src\"] == curr_n_src]\n",
    "#     x = np.arange(len(x_pos_dict)) - 1 + 0.25*(curr_n_src - 3)\n",
    "#     y = curr_src_df[\"adj_corr\"].values\n",
    "#     axes[1].plot(x, y, alpha=0.75, linestyle=\"--\", linewidth=1.5, color=color_dict[curr_n_src],\n",
    "#                  marker=\"o\", markersize=16,\n",
    "#                  markeredgecolor=\"k\", markeredgewidth=2,\n",
    "#                  markerfacecolor=color_dict[curr_n_src])\n",
    "# axes[1].set_title(\"Random-guess adjusted proportions correct\", fontsize=20)\n",
    "# axes[1].set_xticks(x_ticks)\n",
    "# axes[1].set_xticklabels(x_ticklabels, fontsize=16)\n",
    "# axes[1].set_yticks(y_ticks)\n",
    "# axes[1].set_yticklabels((\"{:.1f}\".format(i) for i in y_ticks), fontsize=16)\n",
    "# axes[1].set_ylabel(r\"$\\Delta$ proportion correct\", fontsize=18)\n",
    "# axes[1].set_ylim((0, 0.75))\n",
    "# axes[1].grid(linestyle=\":\", alpha=1)\n",
    "# axes[1].legend(handles=legend0, loc=2, fontsize=16)\n",
    "\n",
    "fig.text(0.5, 0.05,\n",
    "         \"Target movement range\", ha=\"center\", fontsize=20)\n",
    "plt.show()\n",
    "# plt.savefig(\"a.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot as a function of starting location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonstationary_df = cleaned_df[cleaned_df[\"amplitude\"] != 0]\n",
    "amp_series = nonstationary_df.groupby([\"n_src\", \"init_angle\"]).mean()[\"correct\"]/5\n",
    "amp_df = amp_series.to_frame()\n",
    "amp_df = amp_df.stack().reset_index()\n",
    "amp_df = amp_df.drop(columns=\"level_2\")\n",
    "amp_df.columns = [\"n_src\", \"amplitude\", \"prop_corr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dict = {2: \"b\", 3: \"y\", 4: \"r\"}\n",
    "x_pos_dict = {2: -1, 3: 0, 4: 1.25}\n",
    "x_ticks = (-4.5, -3.5, -1, 0, 1, 3.5, 4.5, 5.5, 6.5)\n",
    "x_ticklabels = (r\"$-20^{\\circ}$\", r\"$+20^{\\circ}$\",\n",
    "                r\"$-40^{\\circ}$\", r\"$0^{\\circ}$\", r\"$+40^{\\circ}$\",\n",
    "                r\"$-60^{\\circ}$\", r\"$-20^{\\circ}$\", r\"$+20^{\\circ}$\", r\"$+60^{\\circ}$\")\n",
    "y_ticks = np.linspace(0.1, 0.9, 9)\n",
    "y_ticklabels = [\"{:.1f}\".format(val) for val in y_ticks]\n",
    "legend0 = []\n",
    "legend0.append(Patch(facecolor=\"b\", edgecolor=\"b\", label=\"2 talkers\", alpha=0.7))\n",
    "legend0.append(Patch(facecolor=\"y\", edgecolor=\"y\", label=\"3 talkers\", alpha=0.7))\n",
    "legend0.append(Patch(facecolor=\"r\", edgecolor=\"r\", label=\"4 talkers\", alpha=0.7))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "ax.set_title(\"Performance as a function of target angle\", fontsize=26)\n",
    "for row in amp_df.iterrows():\n",
    "    curr_n_src = int(row[1][0])\n",
    "    curr_init_angle = row[1][1]\n",
    "    curr_prop = row[1][2]\n",
    "    x_pos = 4*x_pos_dict[curr_n_src] + curr_init_angle/40\n",
    "    ax.bar(x_pos, curr_prop, align=\"center\", width=0.8, alpha=0.7, color=color_dict[curr_n_src])\n",
    "ax.set_xticks(x_ticks)\n",
    "ax.set_xticklabels(x_ticklabels, fontsize=16)\n",
    "ax.set_xlabel(\"Mean target angle\", fontsize=18)\n",
    "ax.set_xlim((-6, 8))\n",
    "ax.set_yticks(y_ticks)\n",
    "ax.set_yticklabels(y_ticklabels, fontsize=16)\n",
    "ax.set_ylabel(\"Proportion correct\", fontsize=18)\n",
    "ax.set_ylim((0., 1))\n",
    "ax.grid(linestyle=\":\")\n",
    "ax.legend(handles=legend0, loc=1, fontsize=16)\n",
    "\n",
    "plt.show()\n",
    "# plt.savefig(\"b.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot as a function of word position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = cleaned_df[\"pattern\"].values\n",
    "responses = cleaned_df[\"subj_response\"].values\n",
    "\n",
    "corr_list = []\n",
    "for i in range(len(answers)):\n",
    "    curr_ans = answers[i].split(\" \")\n",
    "    curr_res = responses[i].split(\" \")\n",
    "    corr_arr = np.array([curr_ans[j] == curr_res[j] for j in range(len(curr_ans))], dtype=int)\n",
    "    corr_list.append(corr_arr)\n",
    "\n",
    "class Container:\n",
    "    def __init__(self, arr):\n",
    "        self.arr = arr\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        return Container(self.arr + other.arr)\n",
    "    \n",
    "    def __mult__(self, other):\n",
    "        return Container(self.arr*other)\n",
    "    \n",
    "    def __div__(self, other):\n",
    "        return Container(self.arr/other)\n",
    "\n",
    "\n",
    "corr_list = [Container(arr) for arr in corr_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_order_df = cleaned_df.drop(columns=[\"subj_response\", \"run_num\", \"block_num\", \"trial_num\",\n",
    "                                         \"correct\", \"pattern\", \"init_angle\"])\n",
    "word_order_df.insert(len(word_order_df.columns), \"word_order\", corr_list)\n",
    "word_order_series = word_order_df.groupby([\"n_src\", \"amplitude\"]).sum()[\"word_order\"]\n",
    "word_order_df = word_order_series.to_frame()\n",
    "word_order_df = word_order_df.stack().reset_index()\n",
    "word_order_df = word_order_df.drop(columns=\"level_2\")\n",
    "word_order_df.columns = [\"n_src\", \"amplitude\", \"word_order\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dict = {2: \"b\", 3: \"y\", 4: \"r\"}\n",
    "subplot_row_dict = {2: 2, 3: 1, 4: 0}\n",
    "subplot_col_dict = {0.0: 0, 1.25: 1, 5.: 2, 20.: 3}\n",
    "x_pos = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "fig, axes = plt.subplots(3, 4, figsize=(12, 9))\n",
    "fig.suptitle(\"Performance as a function of word position\", fontsize=24)\n",
    "for row in word_order_df.iterrows():\n",
    "    curr_n_src = int(row[1][0])\n",
    "    curr_amp = row[1][1]\n",
    "#     curr_prop = row[1][2].arr/10 # n repetitions * n blocks/rate\n",
    "    row_i = subplot_row_dict[curr_n_src]\n",
    "    col_j = subplot_col_dict[curr_amp]\n",
    "    axes[row_i, col_j].bar(x_pos, curr_prop, align=\"center\", width=0.8,\n",
    "                           alpha=0.7, color=color_dict[curr_n_src])\n",
    "    \n",
    "    axes[row_i, col_j].set_xticks(x_pos)\n",
    "    if row_i == 2:\n",
    "        axes[row_i, col_j].set_xlabel(\"Target amplitude = {:.1f} deg\".format(curr_amp), fontsize=14)\n",
    "    else:\n",
    "        axes[row_i, col_j].set_xticklabels(())\n",
    "    if col_j == 0:\n",
    "        axes[row_i, col_j].set_ylabel(\"{:d} talkers\".format(curr_n_src), fontsize=14)\n",
    "    else:\n",
    "        axes[row_i, col_j].set_yticklabels(())\n",
    "    axes[row_i, col_j].set_ylim((0, 1))\n",
    "\n",
    "    axes[row_i, col_j].grid(linestyle=\":\")\n",
    "\n",
    "fig.text(0.5, 0.05,\n",
    "         \"Word position\", ha=\"center\", fontsize=20)\n",
    "fig.text(0.05, 0.5,\n",
    "         \"Proportion correct\", va=\"center\", fontsize=20, rotation=90)\n",
    "\n",
    "plt.show()\n",
    "# plt.savefig(\"c.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO\n",
    "* Full model: n_talkers x rate x init_theta x word_pos\n",
    "\n",
    "1 cycle is 80 deg (amplitude of 20 deg):\n",
    "* 0.1 Hz = 8 deg/s\n",
    "\n",
    "* 0.5 Hz = 40 deg/s\n",
    "\n",
    "* 2.5 Hz = 200 deg/s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pilot v6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_condition_data(merged_data, cond):\n",
    "    from functools import partial, reduce\n",
    "    inner_merge = partial(pd.merge, how=\"inner\")\n",
    "    flatten = lambda t: [item for sublist in t for item in sublist] # flattens list of lists in double loop\n",
    "\n",
    "    # Choose the subset of the stimulus database that satisfies the current conditions\n",
    "    conditions = []\n",
    "    conditions.append(merged_data[(merged_data[\"stim_type\"] == cond.stim_type)])\n",
    "    conditions.append(merged_data[(merged_data[\"is_target\"] == True) &\n",
    "                                  (merged_data[\"alt_rate\"] == cond.target_alt_rate)])\n",
    "    conditions.append(merged_data[(merged_data[\"is_target\"] == False) &\n",
    "                                  (merged_data[\"alt_rate\"] == cond.masker_alt_rate)])\n",
    "    if cond.target_init_angle: # if initial angle is specified in conditions, it will be not None\n",
    "        conditions.append(merged_data[(merged_data[\"is_target\"] == True) &\n",
    "                                      (np.abs(merged_data[\"init_angle\"]) == cond.target_init_angle)])\n",
    "    if cond.masker_init_angle:\n",
    "        conditions.append(merged_data[(merged_data[\"is_target\"] == False) &\n",
    "                                      (np.abs(merged_data[\"init_angle\"]) == cond.masker_init_angle)])\n",
    "    subsets = [merged_data.loc[merged_data[\"stim_num\"].isin(cond[\"stim_num\"])]\n",
    "               for cond in conditions]\n",
    "    conditioned_data = reduce(inner_merge, subsets)\n",
    "    conditioned_data = conditioned_data[conditioned_data[\"is_target\"]]\n",
    "    return conditioned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_data = pd.read_csv(PROJ_DIR/\"assets\"/\"stimuli\"/\"stimulus_database.csv\")\n",
    "runs_to_plot = sorted(list(DATA_DIR.glob(\"*.csv\")))\n",
    "\n",
    "run_storage = pd.DataFrame()\n",
    "for run_csv in runs_to_plot:\n",
    "    run_storage = run_storage.append(pd.read_csv(run_csv))\n",
    "merged_data = pd.merge(run_storage, stim_data, how=\"inner\").reset_index(drop=True)\n",
    "\n",
    "subject_list = np.sort(merged_data[\"subject_ID\"].unique())\n",
    "subject_list = [subj for subj in subject_list if \"TRAIN\" not in subj]\n",
    "symbols = [\"o\", \"s\", \"^\", \"v\"]\n",
    "subj_symb_map = dict(zip(subject_list, symbols[:len(subject_list)]))\n",
    "\n",
    "control_em = [extract_condition_data(merged_data, cond) for cond in [PILOT_V6_CONTROLS[0]]]\n",
    "expt_ev_em = [extract_condition_data(merged_data, cond) for cond in PILOT_V6_EV_EM]\n",
    "expt_dv_em = [extract_condition_data(merged_data, cond) for cond in PILOT_V6_DV_EM]\n",
    "control_im = [extract_condition_data(merged_data, cond) for cond in [PILOT_V6_CONTROLS[1]]]\n",
    "expt_ev_im = [extract_condition_data(merged_data, cond) for cond in PILOT_V6_EV_IM]\n",
    "expt_dv_im = [extract_condition_data(merged_data, cond) for cond in PILOT_V6_DV_IM]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot parameters\n",
    "chance = 1/8\n",
    "\n",
    "cyan   = (  0/256, 173/256, 239/256, 0.75)\n",
    "violet = (128/256,   0/256, 128/256, 0.75)\n",
    "\n",
    "x_min, x_max, x_spacing = -0.25, 4.25, 1\n",
    "y_min, y_max, y_spacing = 0, 1, 0.1\n",
    "x_ticks = np.arange(0, 5, x_spacing)\n",
    "y_ticks = np.arange(y_min + y_spacing, y_max, y_spacing)\n",
    "\n",
    "dv0 = r\"\"\"Static\n",
    "\"\"\"\n",
    "dv1 = r\"\"\"0.1\n",
    "\"\"\"\n",
    "dv2 = r\"\"\"0.5\n",
    "\"\"\"\n",
    "dv3 = r\"\"\"1.0\n",
    "\"\"\"\n",
    "dv4 = r\"\"\"2.0\n",
    "\"\"\"\n",
    "ev0 = r\"\"\"Static\n",
    "\"\"\"\n",
    "ev1 = r\"\"\"0.1\n",
    "\"\"\"\n",
    "ev2 = r\"\"\"0.5\n",
    "\"\"\"\n",
    "ev3 = r\"\"\"1.0\n",
    "\"\"\"\n",
    "ev4 = r\"\"\"2.0\n",
    "\"\"\"\n",
    "dv_x_ticklabels = [dv0, dv1, dv2, dv3, dv4]\n",
    "ev_x_ticklabels = [ev0, ev1, ev2, ev3, ev4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(8, 12), constrained_layout=True)\n",
    "\n",
    "ev_em = np.empty((len(subject_list), 5))\n",
    "dv_em = np.empty((len(subject_list), 5))\n",
    "ev_im = np.empty((len(subject_list), 5))\n",
    "dv_im = np.empty((len(subject_list), 5))\n",
    "for subj in subject_list:\n",
    "    curr_subj_control_em = [df[df[\"subject_ID\"] == subj] for df in control_em]\n",
    "    curr_subj_expt_ev_em = [df[df[\"subject_ID\"] == subj] for df in expt_ev_em]\n",
    "    curr_subj_expt_dv_em = [df[df[\"subject_ID\"] == subj] for df in expt_dv_em]\n",
    "    curr_subj_control_im = [df[df[\"subject_ID\"] == subj] for df in control_im]\n",
    "    curr_subj_expt_ev_im = [df[df[\"subject_ID\"] == subj] for df in expt_ev_im]\n",
    "    curr_subj_expt_dv_im = [df[df[\"subject_ID\"] == subj] for df in expt_dv_im]\n",
    "    curr_control_em_corr = np.array([(data[\"correct\"]/4).mean() for data in curr_subj_control_em])\n",
    "    curr_expt_ev_em_corr = np.array([(data[\"correct\"]/4).mean() for data in curr_subj_expt_ev_em])\n",
    "    curr_expt_dv_em_corr = np.array([(data[\"correct\"]/4).mean() for data in curr_subj_expt_dv_em])\n",
    "    curr_control_im_corr = np.array([(data[\"correct\"]/4).mean() for data in curr_subj_control_im])\n",
    "    curr_expt_ev_im_corr = np.array([(data[\"correct\"]/4).mean() for data in curr_subj_expt_ev_im])\n",
    "    curr_expt_dv_im_corr = np.array([(data[\"correct\"]/4).mean() for data in curr_subj_expt_dv_im])\n",
    "\n",
    "    axes[0, 0].plot(x_ticks[0 ], curr_control_em_corr,    color=cyan,\n",
    "                    marker=subj_symb_map[subj], markeredgecolor=\"k\", markeredgewidth=1.25, markersize=8)\n",
    "    axes[0, 0].plot(x_ticks[1:], curr_expt_ev_em_corr,    color=cyan,\n",
    "                    marker=subj_symb_map[subj], markeredgecolor=\"k\", markeredgewidth=1.25, markersize=8)\n",
    "    axes[1, 0].plot(x_ticks[0 ], curr_control_em_corr,    color=violet,\n",
    "                    marker=subj_symb_map[subj], markeredgecolor=\"k\", markeredgewidth=1.25, markersize=8)\n",
    "    axes[1, 0].plot(x_ticks[1:], curr_expt_dv_em_corr,    color=violet,\n",
    "                    marker=subj_symb_map[subj], markeredgecolor=\"k\", markeredgewidth=1.25, markersize=8)\n",
    "    axes[0, 1].plot(x_ticks[0 ], curr_control_im_corr,    color=cyan,\n",
    "                    marker=subj_symb_map[subj], markeredgecolor=\"k\", markeredgewidth=1.25, markersize=8)\n",
    "    axes[0, 1].plot(x_ticks[1:], curr_expt_ev_im_corr,    color=cyan,\n",
    "                    marker=subj_symb_map[subj], markeredgecolor=\"k\", markeredgewidth=1.25, markersize=8)\n",
    "    axes[1, 1].plot(x_ticks[0 ], curr_control_im_corr,    color=violet,\n",
    "                    marker=subj_symb_map[subj], markeredgecolor=\"k\", markeredgewidth=1.25, markersize=8)\n",
    "    axes[1, 1].plot(x_ticks[1:], curr_expt_dv_im_corr,    color=violet,\n",
    "                    marker=subj_symb_map[subj], markeredgecolor=\"k\", markeredgewidth=1.25, markersize=8)\n",
    "\n",
    "fig.suptitle(r\"\\textbf{Word identification performance}\", fontsize=24)\n",
    "axes[0, 0].set_title(r\"(Noise Masker)\",  fontsize=18)\n",
    "axes[0, 1].set_title(r\"(Speech Masker)\", fontsize=18)\n",
    "for i, ax_rows in enumerate(axes):\n",
    "    for j, ax in enumerate(ax_rows):\n",
    "        ax.set_xticks(x_ticks)\n",
    "        if i == 0:\n",
    "#             ax.set_xticklabels(dv_x_ticklabels, fontsize=12)\n",
    "            ax.set_xticklabels([], fontsize=12)\n",
    "        else:\n",
    "            ax.set_xticklabels(ev_x_ticklabels, fontsize=12)\n",
    "        ax.set_yticks(y_ticks)\n",
    "        if j == 0:\n",
    "            ax.set_yticklabels([\"{:.1f}\".format(i) for i in y_ticks], fontsize=16)\n",
    "        else:\n",
    "            ax.set_yticklabels([])\n",
    "        ax.tick_params(axis=\"both\", length=0)\n",
    "        ax.grid(linestyle=\"-\", alpha=0.8)\n",
    "        ax.hlines(chance, x_min, x_max, colors=\"k\", linestyles=\":\")\n",
    "        ax.set_xlim(x_min, x_max)\n",
    "        ax.set_ylim(y_min, y_max)\n",
    "fig.text( 0.5 , -0.01, r\"\\textbf{Target rate [Hz]}\", ha=\"center\", rotation=\"horizontal\", fontsize=18)\n",
    "fig.text(-0.03,  0.5 , r\"\\textbf{Proportion correct}\",  va=\"center\", rotation=\"vertical\",   fontsize=18)\n",
    "\n",
    "plt.show()\n",
    "# fig.savefig(\"data_pilot_v6.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pilot v5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and calculate desired dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_data = pd.read_csv(PROJ_DIR/\"archive\"/\"pilot_v5\"/\"stimuli\"/\"stimulus_database.csv\")\n",
    "runs_to_plot = sorted(list((PROJ_DIR/\"archive\"/\"pilot_v5\"/\"data\").glob(\"*.csv\")))\n",
    "\n",
    "run_storage = pd.DataFrame()\n",
    "for run_csv in runs_to_plot:\n",
    "    run_storage = run_storage.append(pd.read_csv(run_csv))\n",
    "merged_data = pd.merge(run_storage, stim_data, how=\"inner\").reset_index(drop=True)\n",
    "\n",
    "subject_list = np.sort(merged_data[\"subject_ID\"].unique())\n",
    "subject_list = [subj for subj in subject_list if \"TRAIN\" not in subj]\n",
    "symbols = [\"o\", \"s\", \"^\", \"v\"]\n",
    "subj_symb_map = dict(zip(subject_list, symbols[:len(subject_list)]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "CONTROL_EM = [Condition(\"SEM\", 0. , 0. , 45. , 45. ),\n",
    "              Condition(\"SEM\", 0. , 0. , 63.5, 63.5)]\n",
    "EXPT_EV_EM = [Condition(\"SEM\", 0.5, 0.5, None, None),\n",
    "              Condition(\"SEM\", 1. , 1. , None, None),\n",
    "              Condition(\"SEM\", 2. , 2. , None, None),\n",
    "              Condition(\"SEM\", 5. , 5. , None, None)]\n",
    "EXPT_DV_EM = [Condition(\"SEM\", 0.5, 5. , None, None),\n",
    "              Condition(\"SEM\", 1. , 2. , None, None),\n",
    "              Condition(\"SEM\", 2. , 1. , None, None),\n",
    "              Condition(\"SEM\", 5. , 0.5, None, None)]\n",
    "CONTROL_IM = [Condition(\"SIM\", 0. , 0. , 45. , 45. ),\n",
    "              Condition(\"SIM\", 0. , 0. , 63.5, 63.5)]\n",
    "EXPT_EV_IM = [Condition(\"SIM\", 0.5, 0.5, None, None),\n",
    "              Condition(\"SIM\", 1. , 1. , None, None),\n",
    "              Condition(\"SIM\", 2. , 2. , None, None),\n",
    "              Condition(\"SIM\", 5. , 5. , None, None)]\n",
    "EXPT_DV_IM = [Condition(\"SIM\", 0.5, 5. , None, None),\n",
    "              Condition(\"SIM\", 1. , 2. , None, None),\n",
    "              Condition(\"SIM\", 2. , 1. , None, None),\n",
    "              Condition(\"SIM\", 5. , 0.5, None, None)]\n",
    "TRAIN_COND = [Condition(\"SEM\", 0. , 0. , 63.5, 63.5),\n",
    "              Condition(\"SEM\", 1. , 1. , None, None),\n",
    "              Condition(\"SEM\", 1,   2. , None, None),\n",
    "              Condition(\"SEM\", 0. , 0. , 45. , 45. ),\n",
    "              Condition(\"SIM\", 0.5, 0.5, None, None),\n",
    "              Condition(\"SIM\", 0.5, 5. , None, None)]\n",
    "ALL_CONDITIONS = CONTROL_EM + EXPT_EV_EM + EXPT_DV_EM \\\n",
    "               + CONTROL_IM + EXPT_EV_IM + EXPT_DV_IM\n",
    "\n",
    "control_em = [extract_condition_data(merged_data, cond) for cond in CONTROL_EM]\n",
    "expt_ev_em = [extract_condition_data(merged_data, cond) for cond in EXPT_EV_EM]\n",
    "expt_dv_em = [extract_condition_data(merged_data, cond) for cond in EXPT_DV_EM]\n",
    "control_im = [extract_condition_data(merged_data, cond) for cond in CONTROL_IM]\n",
    "expt_ev_im = [extract_condition_data(merged_data, cond) for cond in EXPT_EV_IM]\n",
    "expt_dv_im = [extract_condition_data(merged_data, cond) for cond in EXPT_DV_IM]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot parameters\n",
    "chance = 1/8\n",
    "\n",
    "cyan   = (  0/256, 173/256, 239/256, 0.75)\n",
    "violet = (128/256,   0/256, 128/256, 0.75)\n",
    "\n",
    "x_min, x_max, x_spacing = -0.25, 4.25, 1\n",
    "y_min, y_max, y_spacing = 0, 1, 0.1\n",
    "x_ticks = np.arange(0, 5, x_spacing)\n",
    "y_ticks = np.arange(y_min + y_spacing, y_max, y_spacing)\n",
    "\n",
    "dv0 = r\"\"\"T/ST\n",
    "M/ST\n",
    "($\\Delta\\theta=127^{\\circ}$)\n",
    "\"\"\"\n",
    "dv1 = r\"\"\"T/VS\n",
    "M/VS\n",
    "\"\"\"\n",
    "dv2 = r\"\"\"T/SL\n",
    "M/SL\n",
    "\"\"\"\n",
    "dv3 = r\"\"\"T/FS\n",
    "M/FS\n",
    "\"\"\"\n",
    "dv4 = r\"\"\"T/VF\n",
    "M/VF\n",
    "\"\"\"\n",
    "ev0 = r\"\"\"T/ST\n",
    "M/ST\n",
    "($\\Delta\\theta=90^{\\circ}$)\n",
    "\"\"\"\n",
    "ev1 = r\"\"\"T/VS\n",
    "M/VF\n",
    "\"\"\"\n",
    "ev2 = r\"\"\"T/SL\n",
    "M/FS\n",
    "\"\"\"\n",
    "ev3 = r\"\"\"T/FS\n",
    "M/SL\n",
    "\"\"\"\n",
    "ev4 = r\"\"\"T/VF\n",
    "M/VS\n",
    "\"\"\"\n",
    "dv_x_ticklabels = [dv0, dv1, dv2, dv3, dv4]\n",
    "ev_x_ticklabels = [ev0, ev1, ev2, ev3, ev4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(8, 12), constrained_layout=True)\n",
    "\n",
    "ev_em = np.empty((len(subject_list), 5))\n",
    "dv_em = np.empty((len(subject_list), 5))\n",
    "ev_im = np.empty((len(subject_list), 5))\n",
    "dv_im = np.empty((len(subject_list), 5))\n",
    "for subj in subject_list:\n",
    "    curr_subj_control_em = [df[df[\"subject_ID\"] == subj] for df in control_em]\n",
    "    curr_subj_expt_ev_em = [df[df[\"subject_ID\"] == subj] for df in expt_ev_em]\n",
    "    curr_subj_expt_dv_em = [df[df[\"subject_ID\"] == subj] for df in expt_dv_em]\n",
    "    curr_subj_control_im = [df[df[\"subject_ID\"] == subj] for df in control_im]\n",
    "    curr_subj_expt_ev_im = [df[df[\"subject_ID\"] == subj] for df in expt_ev_im]\n",
    "    curr_subj_expt_dv_im = [df[df[\"subject_ID\"] == subj] for df in expt_dv_im]\n",
    "    curr_control_em_corr = np.array([(data[\"correct\"]/4).mean() for data in curr_subj_control_em])\n",
    "    curr_expt_ev_em_corr = np.array([(data[\"correct\"]/4).mean() for data in curr_subj_expt_ev_em])\n",
    "    curr_expt_dv_em_corr = np.array([(data[\"correct\"]/4).mean() for data in curr_subj_expt_dv_em])\n",
    "    curr_control_im_corr = np.array([(data[\"correct\"]/4).mean() for data in curr_subj_control_im])\n",
    "    curr_expt_ev_im_corr = np.array([(data[\"correct\"]/4).mean() for data in curr_subj_expt_ev_im])\n",
    "    curr_expt_dv_im_corr = np.array([(data[\"correct\"]/4).mean() for data in curr_subj_expt_dv_im])\n",
    "\n",
    "    axes[0, 0].plot(x_ticks[0 ], curr_control_em_corr[1], color=cyan,\n",
    "                    marker=subj_symb_map[subj], markeredgecolor=\"k\", markeredgewidth=1.25, markersize=8)\n",
    "    axes[0, 0].plot(x_ticks[1:], curr_expt_ev_em_corr,    color=cyan,\n",
    "                    marker=subj_symb_map[subj], markeredgecolor=\"k\", markeredgewidth=1.25, markersize=8)\n",
    "    axes[1, 0].plot(x_ticks[0 ], curr_control_em_corr[0], color=violet,\n",
    "                    marker=subj_symb_map[subj], markeredgecolor=\"k\", markeredgewidth=1.25, markersize=8)\n",
    "    axes[1, 0].plot(x_ticks[1:], curr_expt_dv_em_corr,    color=violet,\n",
    "                    marker=subj_symb_map[subj], markeredgecolor=\"k\", markeredgewidth=1.25, markersize=8)\n",
    "    axes[0, 1].plot(x_ticks[0 ], curr_control_im_corr[1], color=cyan,\n",
    "                    marker=subj_symb_map[subj], markeredgecolor=\"k\", markeredgewidth=1.25, markersize=8)\n",
    "    axes[0, 1].plot(x_ticks[1:], curr_expt_ev_im_corr,    color=cyan,\n",
    "                    marker=subj_symb_map[subj], markeredgecolor=\"k\", markeredgewidth=1.25, markersize=8)\n",
    "    axes[1, 1].plot(x_ticks[0 ], curr_control_im_corr[0], color=violet,\n",
    "                    marker=subj_symb_map[subj], markeredgecolor=\"k\", markeredgewidth=1.25, markersize=8)\n",
    "    axes[1, 1].plot(x_ticks[1:], curr_expt_dv_im_corr,    color=violet,\n",
    "                    marker=subj_symb_map[subj], markeredgecolor=\"k\", markeredgewidth=1.25, markersize=8)\n",
    "\n",
    "fig.suptitle(r\"\\textbf{Word identification performance}\", fontsize=24)\n",
    "axes[0, 0].set_title(r\"(Noise Masker)\",  fontsize=18)\n",
    "axes[0, 1].set_title(r\"(Speech Masker)\", fontsize=18)\n",
    "for i, ax_rows in enumerate(axes):\n",
    "    for j, ax in enumerate(ax_rows):\n",
    "        ax.set_xticks(x_ticks)\n",
    "        if i == 0:\n",
    "            ax.set_xticklabels(dv_x_ticklabels, fontsize=12)\n",
    "        else:\n",
    "            ax.set_xticklabels(ev_x_ticklabels, fontsize=12)\n",
    "        ax.set_yticks(y_ticks)\n",
    "        if j == 0:\n",
    "            ax.set_yticklabels([\"{:.1f}\".format(i) for i in y_ticks], fontsize=16)\n",
    "        else:\n",
    "            ax.set_yticklabels([])\n",
    "        ax.tick_params(axis=\"both\", length=0)\n",
    "        ax.grid(linestyle=\"-\", alpha=0.8)\n",
    "        ax.hlines(chance, x_min, x_max, colors=\"k\", linestyles=\":\")\n",
    "        ax.set_xlim(x_min, x_max)\n",
    "        ax.set_ylim(y_min, y_max)\n",
    "fig.text( 0.5 , -0.01, r\"\\textbf{Movement conditions}\", ha=\"center\", rotation=\"horizontal\", fontsize=18)\n",
    "fig.text(-0.03,  0.5 , r\"\\textbf{Proportion correct}\",  va=\"center\", rotation=\"vertical\",   fontsize=18)\n",
    "\n",
    "plt.show()\n",
    "# fig.savefig(\"data_pilot_v5.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pilot v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_data = pd.read_csv(PROJ_DIR/\"archive\"/\"pilot_v4\"/\"stimuli\"/\"stimulus_database.csv\")\n",
    "runs_to_plot = range(7)\n",
    "\n",
    "run_storage = pd.DataFrame()\n",
    "for run_num in runs_to_plot:\n",
    "    run_file_name = \"RUN_\" + str(run_num).zfill(3) + \".csv\"\n",
    "    run_storage = run_storage.append(pd.read_csv(DATA_DIR/run_file_name))\n",
    "merged_data = pd.merge(run_storage, stim_data, how=\"inner\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_condition_data(merged_data, cond):\n",
    "    from functools import partial, reduce\n",
    "    inner_merge = partial(pd.merge, how=\"inner\")\n",
    "    flatten = lambda t: [item for sublist in t for item in sublist] # flattens list of lists in double loop\n",
    "\n",
    "    # Choose the subset of the stimulus database that satisfies the current conditions\n",
    "    conditions = []\n",
    "    conditions.append(merged_data[(merged_data[\"stim_type\"] == cond.stim_type)])\n",
    "    conditions.append(merged_data[(merged_data[\"is_target\"] == True) &\n",
    "                                  (merged_data[\"alt_rate\"] == cond.target_alt_rate)])\n",
    "    conditions.append(merged_data[(merged_data[\"is_target\"] == False) &\n",
    "                                  (merged_data[\"alt_rate\"] == cond.masker_alt_rate)])\n",
    "    if cond.target_init_angle: # if initial angle is specified in conditions, it will be not None\n",
    "        conditions.append(merged_data[(merged_data[\"is_target\"] == True) &\n",
    "                                      (np.abs(merged_data[\"init_angle\"]) == cond.target_init_angle)])\n",
    "    if cond.masker_init_angle:\n",
    "        conditions.append(merged_data[(merged_data[\"is_target\"] == False) &\n",
    "                                      (np.abs(merged_data[\"init_angle\"]) == cond.masker_init_angle)])\n",
    "    subsets = [merged_data.loc[merged_data[\"stim_num\"].isin(cond[\"stim_num\"])]\n",
    "               for cond in conditions]\n",
    "    conditioned_data = reduce(inner_merge, subsets)\n",
    "    conditioned_data = conditioned_data[conditioned_data[\"is_target\"]]\n",
    "    return conditioned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expt111_data_by_cond = [extract_condition_data(merged_data, cond) for cond in EXPT_1_1_1]\n",
    "expt112_data_by_cond = [extract_condition_data(merged_data, cond) for cond in EXPT_1_1_2]\n",
    "expt121_data_by_cond = [extract_condition_data(merged_data, cond) for cond in EXPT_1_2_1]\n",
    "expt122_data_by_cond = [extract_condition_data(merged_data, cond) for cond in EXPT_1_2_2]\n",
    "expt131_data_by_cond = [extract_condition_data(merged_data, cond) for cond in EXPT_1_3_1]\n",
    "expt132_data_by_cond = [extract_condition_data(merged_data, cond) for cond in EXPT_1_3_2]\n",
    "expt212_data_by_cond = [extract_condition_data(merged_data, cond) for cond in EXPT_2_1_2]\n",
    "\n",
    "expt111_corr = np.array([(data[\"correct\"]/4).mean() for data in expt111_data_by_cond])\n",
    "expt112_corr = np.array([(data[\"correct\"]/4).mean() for data in expt112_data_by_cond])\n",
    "expt121_corr = np.array([(data[\"correct\"]/4).mean() for data in expt121_data_by_cond])\n",
    "expt122_corr = np.array([(data[\"correct\"]/4).mean() for data in expt122_data_by_cond])\n",
    "expt131_corr = np.array([(data[\"correct\"]/4).mean() for data in expt131_data_by_cond])\n",
    "expt132_corr = np.array([(data[\"correct\"]/4).mean() for data in expt132_data_by_cond])\n",
    "expt212_corr = np.array([(data[\"correct\"]/4).mean() for data in expt212_data_by_cond])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend0 = []\n",
    "legend0.append(Patch(facecolor=\"r\", edgecolor=\"r\", label=\"Antiphasic\"))\n",
    "legend0.append(Patch(facecolor=\"b\", edgecolor=\"b\", label=\"Static target\"))\n",
    "legend0.append(Patch(facecolor=\"g\", edgecolor=\"g\", label=\"Static masker\"))\n",
    "legend0.append(Line2D([], [], linestyle=\"\", marker=\"d\", markeredgewidth=1.5,\n",
    "                      markeredgecolor=\"k\", markerfacecolor=\"w\", markersize=12,\n",
    "                      label=\"Noise masker\"))\n",
    "legend0.append(Line2D([], [], linestyle=\"\", marker=\"s\", markeredgewidth=1.5,\n",
    "                      markeredgecolor=\"k\", markerfacecolor=\"w\", markersize=12,\n",
    "                      label=\"Speech masker\"))\n",
    "legend0.append(Line2D([], [], linestyle=\"\", marker=\"^\", markeredgewidth=1.5,\n",
    "                      markeredgecolor=\"k\", markerfacecolor=\"k\", markersize=12,\n",
    "                      label=r\"$\\pm 90^{\\circ}$\"))\n",
    "legend0.append(Line2D([], [], linestyle=\"\", marker=\"v\", markeredgewidth=1.5,\n",
    "                      markeredgecolor=\"k\", markerfacecolor=\"k\", markersize=12,\n",
    "                      label=r\"$0^{\\circ}$\"))\n",
    "legend0.append(Line2D([], [], linestyle=\"\", marker=\"o\", markeredgewidth=1.5,\n",
    "                      markeredgecolor=\"k\", markerfacecolor=\"k\", markersize=12,\n",
    "                      label=\"0.5 vs 5 Hz\"))\n",
    "\n",
    "# legend_elements.append(Patch(facecolor=\"b\", edgecolor=\"b\", label=r\"$\\pm 90^{\\circ}$\"),)\n",
    "# legend_elements.append(Patch(facecolor=\"r\", edgecolor=\"r\", label=r\"$0^{\\circ}$\"))\n",
    "# legend_elements.append(Line2D([], [], color=\"k\", linestyle=\":\", label=\"chance\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_w = 0.1\n",
    "pilot_v3_pm = [0.9875, 0.9625]\n",
    "pilot_v3_coloc = [0.85, 0.775]\n",
    "x_locs = np.arange(1, 5)\n",
    "y_locs = np.arange(0.5, 1.01, 0.1)\n",
    "x_ticklabels = [0.5, 1, 2, 5]\n",
    "y_ticklabels = [\"{:.1f}\".format(y_val) for y_val in y_locs]\n",
    "y_ticks_ax1 = np.linspace(-0.3, 0.3, 7, endpoint=True)\n",
    "y_ticklabels_ax1 = [\"{:+.1f}\".format(y_val) for y_val in y_ticks_ax1]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "axes[0].plot([3*delta_w, 3*delta_w], pilot_v3_pm, \"k^\", markersize=12, alpha=0.75)\n",
    "axes[0].plot([4*delta_w, 4*delta_w], pilot_v3_coloc, \"kv\", markersize=12, alpha=0.75)\n",
    "axes[0].plot([5*delta_w, 5*delta_w], expt212_corr , \"ko\", markersize=12, alpha=0.75)\n",
    "axes[0].plot(x_locs - 1*delta_w, expt111_corr, \"rd--\", markersize=12, alpha=0.75)\n",
    "axes[0].plot(x_locs + 0*delta_w, expt121_corr, \"bd--\", markersize=12, alpha=0.75)\n",
    "axes[0].plot(x_locs + 1*delta_w, expt131_corr, \"gd--\", markersize=12, alpha=0.75)\n",
    "axes[0].plot(x_locs - 1*delta_w, expt112_corr, \"rs:\",  markersize=12, alpha=0.75)\n",
    "axes[0].plot(x_locs + 0*delta_w, expt122_corr, \"bs:\",  markersize=12, alpha=0.75)\n",
    "axes[0].plot(x_locs + 1*delta_w, expt132_corr, \"gs:\",  markersize=12, alpha=0.75)\n",
    "\n",
    "axes[0].set_title(\"Words correct - one target, one masker\", fontsize=26)\n",
    "axes[0].set_xlabel(\"Oscillation rate [Hz]\", fontsize=24)\n",
    "axes[0].set_ylabel(\"Proportion correct\", fontsize=24)\n",
    "axes[0].set_xlim((0, x_locs[-1] + 5*delta_w))\n",
    "axes[0].set_ylim((0.5, 1.01))\n",
    "axes[0].set_xticks(x_locs)\n",
    "axes[0].set_yticks(y_locs)\n",
    "axes[0].set_xticklabels(x_ticklabels, fontsize=20)\n",
    "axes[0].set_yticklabels(y_ticklabels, fontsize=20)\n",
    "axes[0].grid(color=\"k\", linestyle=\"-\", alpha=0.25)\n",
    "axes[0].legend(handles=legend0, loc=0, fontsize=18)\n",
    "\n",
    "axes[1].bar(x_locs + 0*delta_w, expt112_corr - expt111_corr,\n",
    "            width=delta_w, color=\"r\", align=\"edge\", alpha=0.75)\n",
    "axes[1].bar(x_locs + 1*delta_w, expt122_corr - expt121_corr,\n",
    "            width=delta_w, color=\"b\", align=\"edge\", alpha=0.75)\n",
    "axes[1].bar(x_locs + 2*delta_w, expt132_corr - expt131_corr,\n",
    "            width=delta_w, color=\"g\", align=\"edge\", alpha=0.75)\n",
    "axes[1].hlines(0, 1*delta_w, x_locs[-1] + 4*delta_w, color=\"k\", alpha=0.8)\n",
    "\n",
    "axes[1].set_title(\"How much easier is SOS vs noise? (i.e. EM vs IM)\", fontsize=26)\n",
    "axes[1].set_xlabel(\"Oscillation rate [Hz]\", fontsize=24)\n",
    "axes[1].set_ylabel(r\"$\\Delta$ prop. correct\", fontsize=24)\n",
    "axes[1].set_xlim((x_locs[0] - 1*delta_w, x_locs[-1] + 4*delta_w))\n",
    "axes[1].set_ylim((-0.31, 0.31))\n",
    "axes[1].set_xticks(x_locs + 1.5*delta_w)\n",
    "axes[1].set_yticks(y_ticks_ax1)\n",
    "axes[1].set_xticklabels(x_ticklabels, fontsize=20)\n",
    "axes[1].set_yticklabels(y_ticklabels_ax1, fontsize=20)\n",
    "axes[1].grid(color=\"k\", linestyle=\"-\", alpha=0.25)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"pilot_v4.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pilot v3 - two or three talkers; also examining randomization effect\n",
    "* Red - two talkers, conditions (alternation rates) are blocked\n",
    "* Blue - two talkers, conditions are randomized within block\n",
    "* Yellow - three talkers, conditions are blocked\n",
    "* Green - three talkers, conditions are randomized within block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_data = pd.read_csv(PROJ_DIR/\"archive\"/\"pilot_v3\"/\"stimuli\"/\"stimulus_database.csv\")\n",
    "runs_to_plot = range(4)\n",
    "\n",
    "run_storage = pd.DataFrame()\n",
    "for run_num in runs_to_plot:\n",
    "    run_file_name = \"RUN_\" + str(run_num).zfill(3) + \".csv\"\n",
    "    run_storage = run_storage.append(pd.read_csv(PROJ_DIR/\"archive\"/\"pilot_v3\"/\"data\"/run_file_name))\n",
    "merged_data = pd.merge(run_storage, stim_data, how=\"inner\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chance_level = 1/8\n",
    "colors = [\"r\", \"b\", \"y\", \"g\", \"m\", \"c\", \"y\", \"k\"]\n",
    "marker_symbols = [\"o\", \"v\", \"^\", \"d\", \"*\", \"x\", \"s\", \"p\"]\n",
    "conditions = [\"colocated\", \"plus_minus_90\", 0.5, 2, 4, 8]\n",
    "x_tick_locs = [-0.5, 9, 0.5, 2, 4, 8]\n",
    "x_tick_labels = [(r\"$\\pm90^{\\circ}$\"), \"co-loc\", \"0.5\", \"2\", \"4\", \"8\"]\n",
    "\n",
    "# legend_elements = []\n",
    "# for i in range(n_runs_to_load):\n",
    "#     legend_elements = [Line2D([], [], linestyle=\"\", marker=marker_symbols[i], markeredgewidth=3, markeredgecolor=\"k\", markerfacecolor=\"w\", markersize=18, label=subjects[i])]\n",
    "# legend_elements.append(Patch(facecolor=\"b\", edgecolor=\"b\", label=r\"$\\pm 90^{\\circ}$\"),)\n",
    "# legend_elements.append(Patch(facecolor=\"r\", edgecolor=\"r\", label=r\"$0^{\\circ}$\"))\n",
    "# legend_elements.append(Line2D([], [], color=\"k\", linestyle=\":\", label=\"chance\"))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 9))\n",
    "\n",
    "for idx, run_num in enumerate(runs_to_plot):\n",
    "    curr_run = merged_data[(merged_data[\"is_target\"] == True) &\n",
    "                           (merged_data[\"run_num\"] == run_num)]\n",
    "    rate_correct = []\n",
    "    for cond in conditions:\n",
    "        if cond == \"colocated\":\n",
    "            curr_cond = curr_run[(curr_run[\"alt_rate\"] == 0) &\n",
    "                                 (curr_run[\"init_angle\"] == 0)]\n",
    "            n_correct = sum(curr_cond[\"correct\"])\n",
    "            n_total = 4*len(curr_cond)\n",
    "            ax.plot(x_tick_locs[1], n_correct/n_total, colors[idx] + marker_symbols[idx])\n",
    "        elif cond == \"plus_minus_90\":\n",
    "            curr_cond = curr_run[(curr_run[\"alt_rate\"] == 0) &\n",
    "                                 (curr_run[\"init_angle\"] != 0)]\n",
    "            n_correct = sum(curr_cond[\"correct\"])\n",
    "            n_total = 4*len(curr_cond)\n",
    "            ax.plot(x_tick_locs[0], n_correct/n_total, colors[idx] + marker_symbols[idx])\n",
    "        else:\n",
    "            curr_cond = curr_run[curr_run[\"alt_rate\"] == cond]\n",
    "            n_correct = sum(curr_cond[\"correct\"])\n",
    "            n_total = 4*len(curr_cond)\n",
    "            rate_correct.append((cond, n_correct/n_total))\n",
    "    rate_correct = np.array(rate_correct)\n",
    "    ax.plot(rate_correct[:, 0], rate_correct[:, 1], colors[idx] + marker_symbols[idx] + \"-\")\n",
    "ax.hlines(chance_level, x_tick_locs[0] - 0.5, x_tick_locs[1] + 0.5, color=\"k\", linestyle=\":\", alpha=0.75)\n",
    "\n",
    "ax.set_title(\"Word by word identification performance\", fontsize=40)\n",
    "ax.set_xlabel(\"Oscillation rate [Hz]\", fontsize=28)\n",
    "ax.set_ylabel(\"Proportion correct\", fontsize=28)\n",
    "ax.set_xlim((x_tick_locs[0] - 0.5, x_tick_locs[1] + 0.5))\n",
    "ax.set_ylim((0, 1))\n",
    "ax.set_xticks(x_tick_locs)\n",
    "ax.set_yticks(np.linspace(0, 1, 11, endpoint=True))\n",
    "ax.set_xticklabels(x_tick_labels, fontsize=20)\n",
    "ax.set_yticklabels(np.linspace(0, 1, 11, endpoint=True), fontsize=20)\n",
    "ax.yaxis.set_major_formatter(FormatStrFormatter(\"%.1f\"))\n",
    "\n",
    "ax.grid(linestyle=\"-\")\n",
    "# ax.legend(handles=legend_elements)\n",
    "\n",
    "# plt.savefig(\"ayc_pilot_v3.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot proportion correct by talker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_talker_2 = merged_data[(merged_data[\"is_target\"] == True) &\n",
    "                                  (merged_data[\"n_srcs\"] == 2)].groupby(\"src\").sum(\"correct\")\n",
    "correct_by_talker_2 = grouped_by_talker_2[\"correct\"]\n",
    "possible_correct_2 = 4*grouped_by_talker_2[\"is_target\"].values\n",
    "prop_correct_by_talker_2 = correct_by_talker_2/possible_correct_2\n",
    "prop_correct_by_talker_2 = prop_correct_by_talker_2.sort_values(ascending=False)\n",
    "\n",
    "grouped_by_talker_3 = merged_data[(merged_data[\"is_target\"] == True) &\n",
    "                                  (merged_data[\"n_srcs\"] == 3)].groupby(\"src\").sum(\"correct\")\n",
    "correct_by_talker_3 = grouped_by_talker_3[\"correct\"]\n",
    "possible_correct_3 = 4*grouped_by_talker_3[\"is_target\"].values\n",
    "prop_correct_by_talker_3 = correct_by_talker_3/possible_correct_3\n",
    "prop_correct_by_talker_3 = prop_correct_by_talker_3.sort_values(ascending=False)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "prop_correct_by_talker_2.plot(kind=\"bar\", ylim=(0, 1), ax=axes[0])\n",
    "prop_correct_by_talker_3.plot(kind=\"bar\", ylim=(0, 1), ax=axes[1])\n",
    "\n",
    "axes[0].set_title(\"Two talkers\")\n",
    "axes[1].set_title(\"Three talkers\")\n",
    "axes[1].set_yticklabels([])\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pilot v2 - three talkers, one co-located masker, one antiphasic masker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_figsize = (12, 8)\n",
    "n_runs_to_load = 1\n",
    "n_trials_per_block = 8\n",
    "n_words_per_trial = 4\n",
    "chance_level = 1/8\n",
    "\n",
    "marker_symbols = [\"o\", \"v\", \"^\", \"d\", \"*\"]\n",
    "subjects = [\"ayc\"]\n",
    "legend_elements = []\n",
    "for i in range(n_runs_to_load):\n",
    "    legend_elements = [Line2D([], [], linestyle=\"\", marker=marker_symbols[i], markeredgewidth=3, markeredgecolor=\"k\", markerfacecolor=\"w\", markersize=18, label=subjects[i])]\n",
    "legend_elements.append(Patch(facecolor=\"b\", edgecolor=\"b\", label=r\"$\\pm 90^{\\circ}$\"),)\n",
    "legend_elements.append(Patch(facecolor=\"r\", edgecolor=\"r\", label=r\"$0^{\\circ}$\"))\n",
    "legend_elements.append(Line2D([], [], color=\"k\", linestyle=\":\", label=\"chance\"))\n",
    "\n",
    "all_run_nums = range(n_runs_to_load)\n",
    "fig, ax = plt.subplots(1, 1, figsize=run_figsize)\n",
    "for run_num in all_run_nums:\n",
    "    run_file_name = \"RUN_\" + str(run_num).zfill(3) + \".csv\"\n",
    "    stim_data = pd.read_csv(PROJ_DIR/\"archive\"/\"pilot_v2\"/\"stimuli\"/\"stimulus_database.csv\")\n",
    "    run_data = pd.read_csv(PROJ_DIR/\"archive\"/\"pilot_v2\"/\"data\"/run_file_name)\n",
    "    \n",
    "    run_stim = stim_data.loc[run_data.stimulus_ID].reset_index()\n",
    "    run_stim = run_stim.drop(labels=[\"index\", \"stim_type\"], axis=1)\n",
    "    run_data = run_data.join(run_stim)\n",
    "    run_data = run_data.drop(labels=[\"run_num\", \"subject_ID\", \"task_type\"], axis=1)\n",
    "\n",
    "    n_blocks = run_data.block_num.max()\n",
    "#     n_max_correct = n_trials_per_block*n_words_per_trial\n",
    "    n_max_correct = n_blocks*n_trials_per_block*n_words_per_trial\n",
    "\n",
    "    # Group data\n",
    "    run_rate_grouped = run_data.groupby(by=\"target_alt_rate\")\n",
    "    rates = list(run_rate_grouped.indices.keys())[1:]\n",
    "    correct   = run_rate_grouped.sum()[\"correct\"].values[1:]\n",
    "    # either ear\n",
    "    antipodal = run_data[(run_data[\"target_alt_rate\"] == 0) & \\\n",
    "                         (run_data[\"target_init_position\"] != 0)][\"correct\"].sum()\n",
    "    # co-located\n",
    "    colocated = run_data[(run_data[\"target_alt_rate\"] == 0) & \\\n",
    "                         (run_data[\"target_init_position\"] == 0)][\"correct\"].sum()\n",
    "\n",
    "    # Plot\n",
    "    ax.plot(rates[ 0] - 1, antipodal/n_max_correct, \"b\" + marker_symbols[run_num], markersize=18)\n",
    "    ax.plot(        rates,   correct/n_max_correct, \"k\" + marker_symbols[run_num] + \"-\", markersize=18)\n",
    "    ax.plot(rates[-1] + 1, colocated/n_max_correct, \"r\" + marker_symbols[run_num], markersize=18)\n",
    "ax.hlines(chance_level, rates[0] - 2*1.75, rates[-1] + 2*1.75, color=\"k\", linestyle=\":\")\n",
    "\n",
    "ax.set_title(\"Word by word identification performance\", fontsize=40)\n",
    "ax.set_xlabel(\"Oscillation rate [Hz]\\n(linear scale)\", fontsize=28)\n",
    "ax.set_ylabel(\"Percent correct\", fontsize=28)\n",
    "ax.set_xlim((rates[0] - 1.75, rates[-1] + 1.75))\n",
    "ax.set_ylim((0, 1))\n",
    "ax.set_xticks(rates)\n",
    "ax.set_xticklabels(rates, rotation=90, fontsize=20)\n",
    "ax.set_yticks(np.linspace(0, 1, 11, endpoint=True))\n",
    "ax.set_yticklabels(np.linspace(0, 1, 11, endpoint=True), fontsize=20)\n",
    "ax.xaxis.set_major_formatter(FormatStrFormatter(\"%.1f\"))\n",
    "ax.yaxis.set_major_formatter(FormatStrFormatter(\"%.1f\"))\n",
    "ax.grid(linestyle=\"-\")\n",
    "ax.legend(handles=legend_elements)\n",
    "# ax.grid(linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "# plt.savefig(\"b.pdf\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
