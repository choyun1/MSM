{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "|| MSM INITIALIZATION\n",
      "================================================================================\n",
      "Setting paths...\n",
      "Importing sigtools...\n",
      "Setting up sounddevice...\n",
      "Importing level adjustments...\n",
      "Setting eligible BUG words...\n",
      "Preparing to create long-term spectrum matched noise...\n",
      "Set values for tone pattern synthesis...\n",
      "Initialization complete!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "# import seaborn as sns\n",
    "# sns.set_theme(context=\"poster\", font_scale=1)\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(\"/home/acho/Sync/KiddLab/MSM/src\")\n",
    "from utils.stim_tools import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pilot v7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_df = pd.read_csv(PROJ_DIR/\"assets\"/\"stimuli\"/\"stimulus_database.csv\")\n",
    "run0 = pd.read_csv(DATA_DIR/\"RUN_000.csv\")\n",
    "run1 = pd.read_csv(DATA_DIR/\"RUN_001.csv\")\n",
    "all_runs = pd.concat([run0, run1], ignore_index=True)\n",
    "all_df = pd.merge(all_runs, stim_df, how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pilot v6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_condition_data(merged_data, cond):\n",
    "    from functools import partial, reduce\n",
    "    inner_merge = partial(pd.merge, how=\"inner\")\n",
    "    flatten = lambda t: [item for sublist in t for item in sublist] # flattens list of lists in double loop\n",
    "\n",
    "    # Choose the subset of the stimulus database that satisfies the current conditions\n",
    "    conditions = []\n",
    "    conditions.append(merged_data[(merged_data[\"stim_type\"] == cond.stim_type)])\n",
    "    conditions.append(merged_data[(merged_data[\"is_target\"] == True) &\n",
    "                                  (merged_data[\"alt_rate\"] == cond.target_alt_rate)])\n",
    "    conditions.append(merged_data[(merged_data[\"is_target\"] == False) &\n",
    "                                  (merged_data[\"alt_rate\"] == cond.masker_alt_rate)])\n",
    "    if cond.target_init_angle: # if initial angle is specified in conditions, it will be not None\n",
    "        conditions.append(merged_data[(merged_data[\"is_target\"] == True) &\n",
    "                                      (np.abs(merged_data[\"init_angle\"]) == cond.target_init_angle)])\n",
    "    if cond.masker_init_angle:\n",
    "        conditions.append(merged_data[(merged_data[\"is_target\"] == False) &\n",
    "                                      (np.abs(merged_data[\"init_angle\"]) == cond.masker_init_angle)])\n",
    "    subsets = [merged_data.loc[merged_data[\"stim_num\"].isin(cond[\"stim_num\"])]\n",
    "               for cond in conditions]\n",
    "    conditioned_data = reduce(inner_merge, subsets)\n",
    "    conditioned_data = conditioned_data[conditioned_data[\"is_target\"]]\n",
    "    return conditioned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_data = pd.read_csv(PROJ_DIR/\"assets\"/\"stimuli\"/\"stimulus_database.csv\")\n",
    "runs_to_plot = sorted(list(DATA_DIR.glob(\"*.csv\")))\n",
    "\n",
    "run_storage = pd.DataFrame()\n",
    "for run_csv in runs_to_plot:\n",
    "    run_storage = run_storage.append(pd.read_csv(run_csv))\n",
    "merged_data = pd.merge(run_storage, stim_data, how=\"inner\").reset_index(drop=True)\n",
    "\n",
    "subject_list = np.sort(merged_data[\"subject_ID\"].unique())\n",
    "subject_list = [subj for subj in subject_list if \"TRAIN\" not in subj]\n",
    "symbols = [\"o\", \"s\", \"^\", \"v\"]\n",
    "subj_symb_map = dict(zip(subject_list, symbols[:len(subject_list)]))\n",
    "\n",
    "control_em = [extract_condition_data(merged_data, cond) for cond in [PILOT_V6_CONTROLS[0]]]\n",
    "expt_ev_em = [extract_condition_data(merged_data, cond) for cond in PILOT_V6_EV_EM]\n",
    "expt_dv_em = [extract_condition_data(merged_data, cond) for cond in PILOT_V6_DV_EM]\n",
    "control_im = [extract_condition_data(merged_data, cond) for cond in [PILOT_V6_CONTROLS[1]]]\n",
    "expt_ev_im = [extract_condition_data(merged_data, cond) for cond in PILOT_V6_EV_IM]\n",
    "expt_dv_im = [extract_condition_data(merged_data, cond) for cond in PILOT_V6_DV_IM]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot parameters\n",
    "chance = 1/8\n",
    "\n",
    "cyan   = (  0/256, 173/256, 239/256, 0.75)\n",
    "violet = (128/256,   0/256, 128/256, 0.75)\n",
    "\n",
    "x_min, x_max, x_spacing = -0.25, 4.25, 1\n",
    "y_min, y_max, y_spacing = 0, 1, 0.1\n",
    "x_ticks = np.arange(0, 5, x_spacing)\n",
    "y_ticks = np.arange(y_min + y_spacing, y_max, y_spacing)\n",
    "\n",
    "dv0 = r\"\"\"Static\n",
    "\"\"\"\n",
    "dv1 = r\"\"\"0.1\n",
    "\"\"\"\n",
    "dv2 = r\"\"\"0.5\n",
    "\"\"\"\n",
    "dv3 = r\"\"\"1.0\n",
    "\"\"\"\n",
    "dv4 = r\"\"\"2.0\n",
    "\"\"\"\n",
    "ev0 = r\"\"\"Static\n",
    "\"\"\"\n",
    "ev1 = r\"\"\"0.1\n",
    "\"\"\"\n",
    "ev2 = r\"\"\"0.5\n",
    "\"\"\"\n",
    "ev3 = r\"\"\"1.0\n",
    "\"\"\"\n",
    "ev4 = r\"\"\"2.0\n",
    "\"\"\"\n",
    "dv_x_ticklabels = [dv0, dv1, dv2, dv3, dv4]\n",
    "ev_x_ticklabels = [ev0, ev1, ev2, ev3, ev4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(8, 12), constrained_layout=True)\n",
    "\n",
    "ev_em = np.empty((len(subject_list), 5))\n",
    "dv_em = np.empty((len(subject_list), 5))\n",
    "ev_im = np.empty((len(subject_list), 5))\n",
    "dv_im = np.empty((len(subject_list), 5))\n",
    "for subj in subject_list:\n",
    "    curr_subj_control_em = [df[df[\"subject_ID\"] == subj] for df in control_em]\n",
    "    curr_subj_expt_ev_em = [df[df[\"subject_ID\"] == subj] for df in expt_ev_em]\n",
    "    curr_subj_expt_dv_em = [df[df[\"subject_ID\"] == subj] for df in expt_dv_em]\n",
    "    curr_subj_control_im = [df[df[\"subject_ID\"] == subj] for df in control_im]\n",
    "    curr_subj_expt_ev_im = [df[df[\"subject_ID\"] == subj] for df in expt_ev_im]\n",
    "    curr_subj_expt_dv_im = [df[df[\"subject_ID\"] == subj] for df in expt_dv_im]\n",
    "    curr_control_em_corr = np.array([(data[\"correct\"]/4).mean() for data in curr_subj_control_em])\n",
    "    curr_expt_ev_em_corr = np.array([(data[\"correct\"]/4).mean() for data in curr_subj_expt_ev_em])\n",
    "    curr_expt_dv_em_corr = np.array([(data[\"correct\"]/4).mean() for data in curr_subj_expt_dv_em])\n",
    "    curr_control_im_corr = np.array([(data[\"correct\"]/4).mean() for data in curr_subj_control_im])\n",
    "    curr_expt_ev_im_corr = np.array([(data[\"correct\"]/4).mean() for data in curr_subj_expt_ev_im])\n",
    "    curr_expt_dv_im_corr = np.array([(data[\"correct\"]/4).mean() for data in curr_subj_expt_dv_im])\n",
    "\n",
    "    axes[0, 0].plot(x_ticks[0 ], curr_control_em_corr,    color=cyan,\n",
    "                    marker=subj_symb_map[subj], markeredgecolor=\"k\", markeredgewidth=1.25, markersize=8)\n",
    "    axes[0, 0].plot(x_ticks[1:], curr_expt_ev_em_corr,    color=cyan,\n",
    "                    marker=subj_symb_map[subj], markeredgecolor=\"k\", markeredgewidth=1.25, markersize=8)\n",
    "    axes[1, 0].plot(x_ticks[0 ], curr_control_em_corr,    color=violet,\n",
    "                    marker=subj_symb_map[subj], markeredgecolor=\"k\", markeredgewidth=1.25, markersize=8)\n",
    "    axes[1, 0].plot(x_ticks[1:], curr_expt_dv_em_corr,    color=violet,\n",
    "                    marker=subj_symb_map[subj], markeredgecolor=\"k\", markeredgewidth=1.25, markersize=8)\n",
    "    axes[0, 1].plot(x_ticks[0 ], curr_control_im_corr,    color=cyan,\n",
    "                    marker=subj_symb_map[subj], markeredgecolor=\"k\", markeredgewidth=1.25, markersize=8)\n",
    "    axes[0, 1].plot(x_ticks[1:], curr_expt_ev_im_corr,    color=cyan,\n",
    "                    marker=subj_symb_map[subj], markeredgecolor=\"k\", markeredgewidth=1.25, markersize=8)\n",
    "    axes[1, 1].plot(x_ticks[0 ], curr_control_im_corr,    color=violet,\n",
    "                    marker=subj_symb_map[subj], markeredgecolor=\"k\", markeredgewidth=1.25, markersize=8)\n",
    "    axes[1, 1].plot(x_ticks[1:], curr_expt_dv_im_corr,    color=violet,\n",
    "                    marker=subj_symb_map[subj], markeredgecolor=\"k\", markeredgewidth=1.25, markersize=8)\n",
    "\n",
    "fig.suptitle(r\"\\textbf{Word identification performance}\", fontsize=24)\n",
    "axes[0, 0].set_title(r\"(Noise Masker)\",  fontsize=18)\n",
    "axes[0, 1].set_title(r\"(Speech Masker)\", fontsize=18)\n",
    "for i, ax_rows in enumerate(axes):\n",
    "    for j, ax in enumerate(ax_rows):\n",
    "        ax.set_xticks(x_ticks)\n",
    "        if i == 0:\n",
    "#             ax.set_xticklabels(dv_x_ticklabels, fontsize=12)\n",
    "            ax.set_xticklabels([], fontsize=12)\n",
    "        else:\n",
    "            ax.set_xticklabels(ev_x_ticklabels, fontsize=12)\n",
    "        ax.set_yticks(y_ticks)\n",
    "        if j == 0:\n",
    "            ax.set_yticklabels([\"{:.1f}\".format(i) for i in y_ticks], fontsize=16)\n",
    "        else:\n",
    "            ax.set_yticklabels([])\n",
    "        ax.tick_params(axis=\"both\", length=0)\n",
    "        ax.grid(linestyle=\"-\", alpha=0.8)\n",
    "        ax.hlines(chance, x_min, x_max, colors=\"k\", linestyles=\":\")\n",
    "        ax.set_xlim(x_min, x_max)\n",
    "        ax.set_ylim(y_min, y_max)\n",
    "fig.text( 0.5 , -0.01, r\"\\textbf{Target rate [Hz]}\", ha=\"center\", rotation=\"horizontal\", fontsize=18)\n",
    "fig.text(-0.03,  0.5 , r\"\\textbf{Proportion correct}\",  va=\"center\", rotation=\"vertical\",   fontsize=18)\n",
    "\n",
    "plt.show()\n",
    "# fig.savefig(\"data_pilot_v6.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pilot v5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and calculate desired dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_data = pd.read_csv(PROJ_DIR/\"archive\"/\"pilot_v5\"/\"stimuli\"/\"stimulus_database.csv\")\n",
    "runs_to_plot = sorted(list((PROJ_DIR/\"archive\"/\"pilot_v5\"/\"data\").glob(\"*.csv\")))\n",
    "\n",
    "run_storage = pd.DataFrame()\n",
    "for run_csv in runs_to_plot:\n",
    "    run_storage = run_storage.append(pd.read_csv(run_csv))\n",
    "merged_data = pd.merge(run_storage, stim_data, how=\"inner\").reset_index(drop=True)\n",
    "\n",
    "subject_list = np.sort(merged_data[\"subject_ID\"].unique())\n",
    "subject_list = [subj for subj in subject_list if \"TRAIN\" not in subj]\n",
    "symbols = [\"o\", \"s\", \"^\", \"v\"]\n",
    "subj_symb_map = dict(zip(subject_list, symbols[:len(subject_list)]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "CONTROL_EM = [Condition(\"SEM\", 0. , 0. , 45. , 45. ),\n",
    "              Condition(\"SEM\", 0. , 0. , 63.5, 63.5)]\n",
    "EXPT_EV_EM = [Condition(\"SEM\", 0.5, 0.5, None, None),\n",
    "              Condition(\"SEM\", 1. , 1. , None, None),\n",
    "              Condition(\"SEM\", 2. , 2. , None, None),\n",
    "              Condition(\"SEM\", 5. , 5. , None, None)]\n",
    "EXPT_DV_EM = [Condition(\"SEM\", 0.5, 5. , None, None),\n",
    "              Condition(\"SEM\", 1. , 2. , None, None),\n",
    "              Condition(\"SEM\", 2. , 1. , None, None),\n",
    "              Condition(\"SEM\", 5. , 0.5, None, None)]\n",
    "CONTROL_IM = [Condition(\"SIM\", 0. , 0. , 45. , 45. ),\n",
    "              Condition(\"SIM\", 0. , 0. , 63.5, 63.5)]\n",
    "EXPT_EV_IM = [Condition(\"SIM\", 0.5, 0.5, None, None),\n",
    "              Condition(\"SIM\", 1. , 1. , None, None),\n",
    "              Condition(\"SIM\", 2. , 2. , None, None),\n",
    "              Condition(\"SIM\", 5. , 5. , None, None)]\n",
    "EXPT_DV_IM = [Condition(\"SIM\", 0.5, 5. , None, None),\n",
    "              Condition(\"SIM\", 1. , 2. , None, None),\n",
    "              Condition(\"SIM\", 2. , 1. , None, None),\n",
    "              Condition(\"SIM\", 5. , 0.5, None, None)]\n",
    "TRAIN_COND = [Condition(\"SEM\", 0. , 0. , 63.5, 63.5),\n",
    "              Condition(\"SEM\", 1. , 1. , None, None),\n",
    "              Condition(\"SEM\", 1,   2. , None, None),\n",
    "              Condition(\"SEM\", 0. , 0. , 45. , 45. ),\n",
    "              Condition(\"SIM\", 0.5, 0.5, None, None),\n",
    "              Condition(\"SIM\", 0.5, 5. , None, None)]\n",
    "ALL_CONDITIONS = CONTROL_EM + EXPT_EV_EM + EXPT_DV_EM \\\n",
    "               + CONTROL_IM + EXPT_EV_IM + EXPT_DV_IM\n",
    "\n",
    "control_em = [extract_condition_data(merged_data, cond) for cond in CONTROL_EM]\n",
    "expt_ev_em = [extract_condition_data(merged_data, cond) for cond in EXPT_EV_EM]\n",
    "expt_dv_em = [extract_condition_data(merged_data, cond) for cond in EXPT_DV_EM]\n",
    "control_im = [extract_condition_data(merged_data, cond) for cond in CONTROL_IM]\n",
    "expt_ev_im = [extract_condition_data(merged_data, cond) for cond in EXPT_EV_IM]\n",
    "expt_dv_im = [extract_condition_data(merged_data, cond) for cond in EXPT_DV_IM]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot parameters\n",
    "chance = 1/8\n",
    "\n",
    "cyan   = (  0/256, 173/256, 239/256, 0.75)\n",
    "violet = (128/256,   0/256, 128/256, 0.75)\n",
    "\n",
    "x_min, x_max, x_spacing = -0.25, 4.25, 1\n",
    "y_min, y_max, y_spacing = 0, 1, 0.1\n",
    "x_ticks = np.arange(0, 5, x_spacing)\n",
    "y_ticks = np.arange(y_min + y_spacing, y_max, y_spacing)\n",
    "\n",
    "dv0 = r\"\"\"T/ST\n",
    "M/ST\n",
    "($\\Delta\\theta=127^{\\circ}$)\n",
    "\"\"\"\n",
    "dv1 = r\"\"\"T/VS\n",
    "M/VS\n",
    "\"\"\"\n",
    "dv2 = r\"\"\"T/SL\n",
    "M/SL\n",
    "\"\"\"\n",
    "dv3 = r\"\"\"T/FS\n",
    "M/FS\n",
    "\"\"\"\n",
    "dv4 = r\"\"\"T/VF\n",
    "M/VF\n",
    "\"\"\"\n",
    "ev0 = r\"\"\"T/ST\n",
    "M/ST\n",
    "($\\Delta\\theta=90^{\\circ}$)\n",
    "\"\"\"\n",
    "ev1 = r\"\"\"T/VS\n",
    "M/VF\n",
    "\"\"\"\n",
    "ev2 = r\"\"\"T/SL\n",
    "M/FS\n",
    "\"\"\"\n",
    "ev3 = r\"\"\"T/FS\n",
    "M/SL\n",
    "\"\"\"\n",
    "ev4 = r\"\"\"T/VF\n",
    "M/VS\n",
    "\"\"\"\n",
    "dv_x_ticklabels = [dv0, dv1, dv2, dv3, dv4]\n",
    "ev_x_ticklabels = [ev0, ev1, ev2, ev3, ev4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(8, 12), constrained_layout=True)\n",
    "\n",
    "ev_em = np.empty((len(subject_list), 5))\n",
    "dv_em = np.empty((len(subject_list), 5))\n",
    "ev_im = np.empty((len(subject_list), 5))\n",
    "dv_im = np.empty((len(subject_list), 5))\n",
    "for subj in subject_list:\n",
    "    curr_subj_control_em = [df[df[\"subject_ID\"] == subj] for df in control_em]\n",
    "    curr_subj_expt_ev_em = [df[df[\"subject_ID\"] == subj] for df in expt_ev_em]\n",
    "    curr_subj_expt_dv_em = [df[df[\"subject_ID\"] == subj] for df in expt_dv_em]\n",
    "    curr_subj_control_im = [df[df[\"subject_ID\"] == subj] for df in control_im]\n",
    "    curr_subj_expt_ev_im = [df[df[\"subject_ID\"] == subj] for df in expt_ev_im]\n",
    "    curr_subj_expt_dv_im = [df[df[\"subject_ID\"] == subj] for df in expt_dv_im]\n",
    "    curr_control_em_corr = np.array([(data[\"correct\"]/4).mean() for data in curr_subj_control_em])\n",
    "    curr_expt_ev_em_corr = np.array([(data[\"correct\"]/4).mean() for data in curr_subj_expt_ev_em])\n",
    "    curr_expt_dv_em_corr = np.array([(data[\"correct\"]/4).mean() for data in curr_subj_expt_dv_em])\n",
    "    curr_control_im_corr = np.array([(data[\"correct\"]/4).mean() for data in curr_subj_control_im])\n",
    "    curr_expt_ev_im_corr = np.array([(data[\"correct\"]/4).mean() for data in curr_subj_expt_ev_im])\n",
    "    curr_expt_dv_im_corr = np.array([(data[\"correct\"]/4).mean() for data in curr_subj_expt_dv_im])\n",
    "\n",
    "    axes[0, 0].plot(x_ticks[0 ], curr_control_em_corr[1], color=cyan,\n",
    "                    marker=subj_symb_map[subj], markeredgecolor=\"k\", markeredgewidth=1.25, markersize=8)\n",
    "    axes[0, 0].plot(x_ticks[1:], curr_expt_ev_em_corr,    color=cyan,\n",
    "                    marker=subj_symb_map[subj], markeredgecolor=\"k\", markeredgewidth=1.25, markersize=8)\n",
    "    axes[1, 0].plot(x_ticks[0 ], curr_control_em_corr[0], color=violet,\n",
    "                    marker=subj_symb_map[subj], markeredgecolor=\"k\", markeredgewidth=1.25, markersize=8)\n",
    "    axes[1, 0].plot(x_ticks[1:], curr_expt_dv_em_corr,    color=violet,\n",
    "                    marker=subj_symb_map[subj], markeredgecolor=\"k\", markeredgewidth=1.25, markersize=8)\n",
    "    axes[0, 1].plot(x_ticks[0 ], curr_control_im_corr[1], color=cyan,\n",
    "                    marker=subj_symb_map[subj], markeredgecolor=\"k\", markeredgewidth=1.25, markersize=8)\n",
    "    axes[0, 1].plot(x_ticks[1:], curr_expt_ev_im_corr,    color=cyan,\n",
    "                    marker=subj_symb_map[subj], markeredgecolor=\"k\", markeredgewidth=1.25, markersize=8)\n",
    "    axes[1, 1].plot(x_ticks[0 ], curr_control_im_corr[0], color=violet,\n",
    "                    marker=subj_symb_map[subj], markeredgecolor=\"k\", markeredgewidth=1.25, markersize=8)\n",
    "    axes[1, 1].plot(x_ticks[1:], curr_expt_dv_im_corr,    color=violet,\n",
    "                    marker=subj_symb_map[subj], markeredgecolor=\"k\", markeredgewidth=1.25, markersize=8)\n",
    "\n",
    "fig.suptitle(r\"\\textbf{Word identification performance}\", fontsize=24)\n",
    "axes[0, 0].set_title(r\"(Noise Masker)\",  fontsize=18)\n",
    "axes[0, 1].set_title(r\"(Speech Masker)\", fontsize=18)\n",
    "for i, ax_rows in enumerate(axes):\n",
    "    for j, ax in enumerate(ax_rows):\n",
    "        ax.set_xticks(x_ticks)\n",
    "        if i == 0:\n",
    "            ax.set_xticklabels(dv_x_ticklabels, fontsize=12)\n",
    "        else:\n",
    "            ax.set_xticklabels(ev_x_ticklabels, fontsize=12)\n",
    "        ax.set_yticks(y_ticks)\n",
    "        if j == 0:\n",
    "            ax.set_yticklabels([\"{:.1f}\".format(i) for i in y_ticks], fontsize=16)\n",
    "        else:\n",
    "            ax.set_yticklabels([])\n",
    "        ax.tick_params(axis=\"both\", length=0)\n",
    "        ax.grid(linestyle=\"-\", alpha=0.8)\n",
    "        ax.hlines(chance, x_min, x_max, colors=\"k\", linestyles=\":\")\n",
    "        ax.set_xlim(x_min, x_max)\n",
    "        ax.set_ylim(y_min, y_max)\n",
    "fig.text( 0.5 , -0.01, r\"\\textbf{Movement conditions}\", ha=\"center\", rotation=\"horizontal\", fontsize=18)\n",
    "fig.text(-0.03,  0.5 , r\"\\textbf{Proportion correct}\",  va=\"center\", rotation=\"vertical\",   fontsize=18)\n",
    "\n",
    "plt.show()\n",
    "# fig.savefig(\"data_pilot_v5.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pilot v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_data = pd.read_csv(PROJ_DIR/\"archive\"/\"pilot_v4\"/\"stimuli\"/\"stimulus_database.csv\")\n",
    "runs_to_plot = range(7)\n",
    "\n",
    "run_storage = pd.DataFrame()\n",
    "for run_num in runs_to_plot:\n",
    "    run_file_name = \"RUN_\" + str(run_num).zfill(3) + \".csv\"\n",
    "    run_storage = run_storage.append(pd.read_csv(DATA_DIR/run_file_name))\n",
    "merged_data = pd.merge(run_storage, stim_data, how=\"inner\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_condition_data(merged_data, cond):\n",
    "    from functools import partial, reduce\n",
    "    inner_merge = partial(pd.merge, how=\"inner\")\n",
    "    flatten = lambda t: [item for sublist in t for item in sublist] # flattens list of lists in double loop\n",
    "\n",
    "    # Choose the subset of the stimulus database that satisfies the current conditions\n",
    "    conditions = []\n",
    "    conditions.append(merged_data[(merged_data[\"stim_type\"] == cond.stim_type)])\n",
    "    conditions.append(merged_data[(merged_data[\"is_target\"] == True) &\n",
    "                                  (merged_data[\"alt_rate\"] == cond.target_alt_rate)])\n",
    "    conditions.append(merged_data[(merged_data[\"is_target\"] == False) &\n",
    "                                  (merged_data[\"alt_rate\"] == cond.masker_alt_rate)])\n",
    "    if cond.target_init_angle: # if initial angle is specified in conditions, it will be not None\n",
    "        conditions.append(merged_data[(merged_data[\"is_target\"] == True) &\n",
    "                                      (np.abs(merged_data[\"init_angle\"]) == cond.target_init_angle)])\n",
    "    if cond.masker_init_angle:\n",
    "        conditions.append(merged_data[(merged_data[\"is_target\"] == False) &\n",
    "                                      (np.abs(merged_data[\"init_angle\"]) == cond.masker_init_angle)])\n",
    "    subsets = [merged_data.loc[merged_data[\"stim_num\"].isin(cond[\"stim_num\"])]\n",
    "               for cond in conditions]\n",
    "    conditioned_data = reduce(inner_merge, subsets)\n",
    "    conditioned_data = conditioned_data[conditioned_data[\"is_target\"]]\n",
    "    return conditioned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expt111_data_by_cond = [extract_condition_data(merged_data, cond) for cond in EXPT_1_1_1]\n",
    "expt112_data_by_cond = [extract_condition_data(merged_data, cond) for cond in EXPT_1_1_2]\n",
    "expt121_data_by_cond = [extract_condition_data(merged_data, cond) for cond in EXPT_1_2_1]\n",
    "expt122_data_by_cond = [extract_condition_data(merged_data, cond) for cond in EXPT_1_2_2]\n",
    "expt131_data_by_cond = [extract_condition_data(merged_data, cond) for cond in EXPT_1_3_1]\n",
    "expt132_data_by_cond = [extract_condition_data(merged_data, cond) for cond in EXPT_1_3_2]\n",
    "expt212_data_by_cond = [extract_condition_data(merged_data, cond) for cond in EXPT_2_1_2]\n",
    "\n",
    "expt111_corr = np.array([(data[\"correct\"]/4).mean() for data in expt111_data_by_cond])\n",
    "expt112_corr = np.array([(data[\"correct\"]/4).mean() for data in expt112_data_by_cond])\n",
    "expt121_corr = np.array([(data[\"correct\"]/4).mean() for data in expt121_data_by_cond])\n",
    "expt122_corr = np.array([(data[\"correct\"]/4).mean() for data in expt122_data_by_cond])\n",
    "expt131_corr = np.array([(data[\"correct\"]/4).mean() for data in expt131_data_by_cond])\n",
    "expt132_corr = np.array([(data[\"correct\"]/4).mean() for data in expt132_data_by_cond])\n",
    "expt212_corr = np.array([(data[\"correct\"]/4).mean() for data in expt212_data_by_cond])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend0 = []\n",
    "legend0.append(Patch(facecolor=\"r\", edgecolor=\"r\", label=\"Antiphasic\"))\n",
    "legend0.append(Patch(facecolor=\"b\", edgecolor=\"b\", label=\"Static target\"))\n",
    "legend0.append(Patch(facecolor=\"g\", edgecolor=\"g\", label=\"Static masker\"))\n",
    "legend0.append(Line2D([], [], linestyle=\"\", marker=\"d\", markeredgewidth=1.5,\n",
    "                      markeredgecolor=\"k\", markerfacecolor=\"w\", markersize=12,\n",
    "                      label=\"Noise masker\"))\n",
    "legend0.append(Line2D([], [], linestyle=\"\", marker=\"s\", markeredgewidth=1.5,\n",
    "                      markeredgecolor=\"k\", markerfacecolor=\"w\", markersize=12,\n",
    "                      label=\"Speech masker\"))\n",
    "legend0.append(Line2D([], [], linestyle=\"\", marker=\"^\", markeredgewidth=1.5,\n",
    "                      markeredgecolor=\"k\", markerfacecolor=\"k\", markersize=12,\n",
    "                      label=r\"$\\pm 90^{\\circ}$\"))\n",
    "legend0.append(Line2D([], [], linestyle=\"\", marker=\"v\", markeredgewidth=1.5,\n",
    "                      markeredgecolor=\"k\", markerfacecolor=\"k\", markersize=12,\n",
    "                      label=r\"$0^{\\circ}$\"))\n",
    "legend0.append(Line2D([], [], linestyle=\"\", marker=\"o\", markeredgewidth=1.5,\n",
    "                      markeredgecolor=\"k\", markerfacecolor=\"k\", markersize=12,\n",
    "                      label=\"0.5 vs 5 Hz\"))\n",
    "\n",
    "# legend_elements.append(Patch(facecolor=\"b\", edgecolor=\"b\", label=r\"$\\pm 90^{\\circ}$\"),)\n",
    "# legend_elements.append(Patch(facecolor=\"r\", edgecolor=\"r\", label=r\"$0^{\\circ}$\"))\n",
    "# legend_elements.append(Line2D([], [], color=\"k\", linestyle=\":\", label=\"chance\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_w = 0.1\n",
    "pilot_v3_pm = [0.9875, 0.9625]\n",
    "pilot_v3_coloc = [0.85, 0.775]\n",
    "x_locs = np.arange(1, 5)\n",
    "y_locs = np.arange(0.5, 1.01, 0.1)\n",
    "x_ticklabels = [0.5, 1, 2, 5]\n",
    "y_ticklabels = [\"{:.1f}\".format(y_val) for y_val in y_locs]\n",
    "y_ticks_ax1 = np.linspace(-0.3, 0.3, 7, endpoint=True)\n",
    "y_ticklabels_ax1 = [\"{:+.1f}\".format(y_val) for y_val in y_ticks_ax1]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "axes[0].plot([3*delta_w, 3*delta_w], pilot_v3_pm, \"k^\", markersize=12, alpha=0.75)\n",
    "axes[0].plot([4*delta_w, 4*delta_w], pilot_v3_coloc, \"kv\", markersize=12, alpha=0.75)\n",
    "axes[0].plot([5*delta_w, 5*delta_w], expt212_corr , \"ko\", markersize=12, alpha=0.75)\n",
    "axes[0].plot(x_locs - 1*delta_w, expt111_corr, \"rd--\", markersize=12, alpha=0.75)\n",
    "axes[0].plot(x_locs + 0*delta_w, expt121_corr, \"bd--\", markersize=12, alpha=0.75)\n",
    "axes[0].plot(x_locs + 1*delta_w, expt131_corr, \"gd--\", markersize=12, alpha=0.75)\n",
    "axes[0].plot(x_locs - 1*delta_w, expt112_corr, \"rs:\",  markersize=12, alpha=0.75)\n",
    "axes[0].plot(x_locs + 0*delta_w, expt122_corr, \"bs:\",  markersize=12, alpha=0.75)\n",
    "axes[0].plot(x_locs + 1*delta_w, expt132_corr, \"gs:\",  markersize=12, alpha=0.75)\n",
    "\n",
    "axes[0].set_title(\"Words correct - one target, one masker\", fontsize=26)\n",
    "axes[0].set_xlabel(\"Oscillation rate [Hz]\", fontsize=24)\n",
    "axes[0].set_ylabel(\"Proportion correct\", fontsize=24)\n",
    "axes[0].set_xlim((0, x_locs[-1] + 5*delta_w))\n",
    "axes[0].set_ylim((0.5, 1.01))\n",
    "axes[0].set_xticks(x_locs)\n",
    "axes[0].set_yticks(y_locs)\n",
    "axes[0].set_xticklabels(x_ticklabels, fontsize=20)\n",
    "axes[0].set_yticklabels(y_ticklabels, fontsize=20)\n",
    "axes[0].grid(color=\"k\", linestyle=\"-\", alpha=0.25)\n",
    "axes[0].legend(handles=legend0, loc=0, fontsize=18)\n",
    "\n",
    "axes[1].bar(x_locs + 0*delta_w, expt112_corr - expt111_corr,\n",
    "            width=delta_w, color=\"r\", align=\"edge\", alpha=0.75)\n",
    "axes[1].bar(x_locs + 1*delta_w, expt122_corr - expt121_corr,\n",
    "            width=delta_w, color=\"b\", align=\"edge\", alpha=0.75)\n",
    "axes[1].bar(x_locs + 2*delta_w, expt132_corr - expt131_corr,\n",
    "            width=delta_w, color=\"g\", align=\"edge\", alpha=0.75)\n",
    "axes[1].hlines(0, 1*delta_w, x_locs[-1] + 4*delta_w, color=\"k\", alpha=0.8)\n",
    "\n",
    "axes[1].set_title(\"How much easier is SOS vs noise? (i.e. EM vs IM)\", fontsize=26)\n",
    "axes[1].set_xlabel(\"Oscillation rate [Hz]\", fontsize=24)\n",
    "axes[1].set_ylabel(r\"$\\Delta$ prop. correct\", fontsize=24)\n",
    "axes[1].set_xlim((x_locs[0] - 1*delta_w, x_locs[-1] + 4*delta_w))\n",
    "axes[1].set_ylim((-0.31, 0.31))\n",
    "axes[1].set_xticks(x_locs + 1.5*delta_w)\n",
    "axes[1].set_yticks(y_ticks_ax1)\n",
    "axes[1].set_xticklabels(x_ticklabels, fontsize=20)\n",
    "axes[1].set_yticklabels(y_ticklabels_ax1, fontsize=20)\n",
    "axes[1].grid(color=\"k\", linestyle=\"-\", alpha=0.25)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"pilot_v4.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pilot v3 - two or three talkers; also examining randomization effect\n",
    "* Red - two talkers, conditions (alternation rates) are blocked\n",
    "* Blue - two talkers, conditions are randomized within block\n",
    "* Yellow - three talkers, conditions are blocked\n",
    "* Green - three talkers, conditions are randomized within block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_data = pd.read_csv(PROJ_DIR/\"archive\"/\"pilot_v3\"/\"stimuli\"/\"stimulus_database.csv\")\n",
    "runs_to_plot = range(4)\n",
    "\n",
    "run_storage = pd.DataFrame()\n",
    "for run_num in runs_to_plot:\n",
    "    run_file_name = \"RUN_\" + str(run_num).zfill(3) + \".csv\"\n",
    "    run_storage = run_storage.append(pd.read_csv(PROJ_DIR/\"archive\"/\"pilot_v3\"/\"data\"/run_file_name))\n",
    "merged_data = pd.merge(run_storage, stim_data, how=\"inner\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chance_level = 1/8\n",
    "colors = [\"r\", \"b\", \"y\", \"g\", \"m\", \"c\", \"y\", \"k\"]\n",
    "marker_symbols = [\"o\", \"v\", \"^\", \"d\", \"*\", \"x\", \"s\", \"p\"]\n",
    "conditions = [\"colocated\", \"plus_minus_90\", 0.5, 2, 4, 8]\n",
    "x_tick_locs = [-0.5, 9, 0.5, 2, 4, 8]\n",
    "x_tick_labels = [(r\"$\\pm90^{\\circ}$\"), \"co-loc\", \"0.5\", \"2\", \"4\", \"8\"]\n",
    "\n",
    "# legend_elements = []\n",
    "# for i in range(n_runs_to_load):\n",
    "#     legend_elements = [Line2D([], [], linestyle=\"\", marker=marker_symbols[i], markeredgewidth=3, markeredgecolor=\"k\", markerfacecolor=\"w\", markersize=18, label=subjects[i])]\n",
    "# legend_elements.append(Patch(facecolor=\"b\", edgecolor=\"b\", label=r\"$\\pm 90^{\\circ}$\"),)\n",
    "# legend_elements.append(Patch(facecolor=\"r\", edgecolor=\"r\", label=r\"$0^{\\circ}$\"))\n",
    "# legend_elements.append(Line2D([], [], color=\"k\", linestyle=\":\", label=\"chance\"))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 9))\n",
    "\n",
    "for idx, run_num in enumerate(runs_to_plot):\n",
    "    curr_run = merged_data[(merged_data[\"is_target\"] == True) &\n",
    "                           (merged_data[\"run_num\"] == run_num)]\n",
    "    rate_correct = []\n",
    "    for cond in conditions:\n",
    "        if cond == \"colocated\":\n",
    "            curr_cond = curr_run[(curr_run[\"alt_rate\"] == 0) &\n",
    "                                 (curr_run[\"init_angle\"] == 0)]\n",
    "            n_correct = sum(curr_cond[\"correct\"])\n",
    "            n_total = 4*len(curr_cond)\n",
    "            ax.plot(x_tick_locs[1], n_correct/n_total, colors[idx] + marker_symbols[idx])\n",
    "        elif cond == \"plus_minus_90\":\n",
    "            curr_cond = curr_run[(curr_run[\"alt_rate\"] == 0) &\n",
    "                                 (curr_run[\"init_angle\"] != 0)]\n",
    "            n_correct = sum(curr_cond[\"correct\"])\n",
    "            n_total = 4*len(curr_cond)\n",
    "            ax.plot(x_tick_locs[0], n_correct/n_total, colors[idx] + marker_symbols[idx])\n",
    "        else:\n",
    "            curr_cond = curr_run[curr_run[\"alt_rate\"] == cond]\n",
    "            n_correct = sum(curr_cond[\"correct\"])\n",
    "            n_total = 4*len(curr_cond)\n",
    "            rate_correct.append((cond, n_correct/n_total))\n",
    "    rate_correct = np.array(rate_correct)\n",
    "    ax.plot(rate_correct[:, 0], rate_correct[:, 1], colors[idx] + marker_symbols[idx] + \"-\")\n",
    "ax.hlines(chance_level, x_tick_locs[0] - 0.5, x_tick_locs[1] + 0.5, color=\"k\", linestyle=\":\", alpha=0.75)\n",
    "\n",
    "ax.set_title(\"Word by word identification performance\", fontsize=40)\n",
    "ax.set_xlabel(\"Oscillation rate [Hz]\", fontsize=28)\n",
    "ax.set_ylabel(\"Proportion correct\", fontsize=28)\n",
    "ax.set_xlim((x_tick_locs[0] - 0.5, x_tick_locs[1] + 0.5))\n",
    "ax.set_ylim((0, 1))\n",
    "ax.set_xticks(x_tick_locs)\n",
    "ax.set_yticks(np.linspace(0, 1, 11, endpoint=True))\n",
    "ax.set_xticklabels(x_tick_labels, fontsize=20)\n",
    "ax.set_yticklabels(np.linspace(0, 1, 11, endpoint=True), fontsize=20)\n",
    "ax.yaxis.set_major_formatter(FormatStrFormatter(\"%.1f\"))\n",
    "\n",
    "ax.grid(linestyle=\"-\")\n",
    "# ax.legend(handles=legend_elements)\n",
    "\n",
    "# plt.savefig(\"ayc_pilot_v3.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot proportion correct by talker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_talker_2 = merged_data[(merged_data[\"is_target\"] == True) &\n",
    "                                  (merged_data[\"n_srcs\"] == 2)].groupby(\"src\").sum(\"correct\")\n",
    "correct_by_talker_2 = grouped_by_talker_2[\"correct\"]\n",
    "possible_correct_2 = 4*grouped_by_talker_2[\"is_target\"].values\n",
    "prop_correct_by_talker_2 = correct_by_talker_2/possible_correct_2\n",
    "prop_correct_by_talker_2 = prop_correct_by_talker_2.sort_values(ascending=False)\n",
    "\n",
    "grouped_by_talker_3 = merged_data[(merged_data[\"is_target\"] == True) &\n",
    "                                  (merged_data[\"n_srcs\"] == 3)].groupby(\"src\").sum(\"correct\")\n",
    "correct_by_talker_3 = grouped_by_talker_3[\"correct\"]\n",
    "possible_correct_3 = 4*grouped_by_talker_3[\"is_target\"].values\n",
    "prop_correct_by_talker_3 = correct_by_talker_3/possible_correct_3\n",
    "prop_correct_by_talker_3 = prop_correct_by_talker_3.sort_values(ascending=False)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "prop_correct_by_talker_2.plot(kind=\"bar\", ylim=(0, 1), ax=axes[0])\n",
    "prop_correct_by_talker_3.plot(kind=\"bar\", ylim=(0, 1), ax=axes[1])\n",
    "\n",
    "axes[0].set_title(\"Two talkers\")\n",
    "axes[1].set_title(\"Three talkers\")\n",
    "axes[1].set_yticklabels([])\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pilot v2 - three talkers, one co-located masker, one antiphasic masker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_figsize = (12, 8)\n",
    "n_runs_to_load = 1\n",
    "n_trials_per_block = 8\n",
    "n_words_per_trial = 4\n",
    "chance_level = 1/8\n",
    "\n",
    "marker_symbols = [\"o\", \"v\", \"^\", \"d\", \"*\"]\n",
    "subjects = [\"ayc\"]\n",
    "legend_elements = []\n",
    "for i in range(n_runs_to_load):\n",
    "    legend_elements = [Line2D([], [], linestyle=\"\", marker=marker_symbols[i], markeredgewidth=3, markeredgecolor=\"k\", markerfacecolor=\"w\", markersize=18, label=subjects[i])]\n",
    "legend_elements.append(Patch(facecolor=\"b\", edgecolor=\"b\", label=r\"$\\pm 90^{\\circ}$\"),)\n",
    "legend_elements.append(Patch(facecolor=\"r\", edgecolor=\"r\", label=r\"$0^{\\circ}$\"))\n",
    "legend_elements.append(Line2D([], [], color=\"k\", linestyle=\":\", label=\"chance\"))\n",
    "\n",
    "all_run_nums = range(n_runs_to_load)\n",
    "fig, ax = plt.subplots(1, 1, figsize=run_figsize)\n",
    "for run_num in all_run_nums:\n",
    "    run_file_name = \"RUN_\" + str(run_num).zfill(3) + \".csv\"\n",
    "    stim_data = pd.read_csv(PROJ_DIR/\"archive\"/\"pilot_v2\"/\"stimuli\"/\"stimulus_database.csv\")\n",
    "    run_data = pd.read_csv(PROJ_DIR/\"archive\"/\"pilot_v2\"/\"data\"/run_file_name)\n",
    "    \n",
    "    run_stim = stim_data.loc[run_data.stimulus_ID].reset_index()\n",
    "    run_stim = run_stim.drop(labels=[\"index\", \"stim_type\"], axis=1)\n",
    "    run_data = run_data.join(run_stim)\n",
    "    run_data = run_data.drop(labels=[\"run_num\", \"subject_ID\", \"task_type\"], axis=1)\n",
    "\n",
    "    n_blocks = run_data.block_num.max()\n",
    "#     n_max_correct = n_trials_per_block*n_words_per_trial\n",
    "    n_max_correct = n_blocks*n_trials_per_block*n_words_per_trial\n",
    "\n",
    "    # Group data\n",
    "    run_rate_grouped = run_data.groupby(by=\"target_alt_rate\")\n",
    "    rates = list(run_rate_grouped.indices.keys())[1:]\n",
    "    correct   = run_rate_grouped.sum()[\"correct\"].values[1:]\n",
    "    # either ear\n",
    "    antipodal = run_data[(run_data[\"target_alt_rate\"] == 0) & \\\n",
    "                         (run_data[\"target_init_position\"] != 0)][\"correct\"].sum()\n",
    "    # co-located\n",
    "    colocated = run_data[(run_data[\"target_alt_rate\"] == 0) & \\\n",
    "                         (run_data[\"target_init_position\"] == 0)][\"correct\"].sum()\n",
    "\n",
    "    # Plot\n",
    "    ax.plot(rates[ 0] - 1, antipodal/n_max_correct, \"b\" + marker_symbols[run_num], markersize=18)\n",
    "    ax.plot(        rates,   correct/n_max_correct, \"k\" + marker_symbols[run_num] + \"-\", markersize=18)\n",
    "    ax.plot(rates[-1] + 1, colocated/n_max_correct, \"r\" + marker_symbols[run_num], markersize=18)\n",
    "ax.hlines(chance_level, rates[0] - 2*1.75, rates[-1] + 2*1.75, color=\"k\", linestyle=\":\")\n",
    "\n",
    "ax.set_title(\"Word by word identification performance\", fontsize=40)\n",
    "ax.set_xlabel(\"Oscillation rate [Hz]\\n(linear scale)\", fontsize=28)\n",
    "ax.set_ylabel(\"Percent correct\", fontsize=28)\n",
    "ax.set_xlim((rates[0] - 1.75, rates[-1] + 1.75))\n",
    "ax.set_ylim((0, 1))\n",
    "ax.set_xticks(rates)\n",
    "ax.set_xticklabels(rates, rotation=90, fontsize=20)\n",
    "ax.set_yticks(np.linspace(0, 1, 11, endpoint=True))\n",
    "ax.set_yticklabels(np.linspace(0, 1, 11, endpoint=True), fontsize=20)\n",
    "ax.xaxis.set_major_formatter(FormatStrFormatter(\"%.1f\"))\n",
    "ax.yaxis.set_major_formatter(FormatStrFormatter(\"%.1f\"))\n",
    "ax.grid(linestyle=\"-\")\n",
    "ax.legend(handles=legend_elements)\n",
    "# ax.grid(linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "# plt.savefig(\"b.pdf\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
